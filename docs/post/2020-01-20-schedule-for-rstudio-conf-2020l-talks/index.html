<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Schedule for rstudio::conf(2020L) talks - DL;DS</title>
  <meta name="description" content="&lt;p&gt;The &lt;a href=&#39;https://rstudio.com/conference/&#39;&gt;RStudio conference&lt;/a&gt; is coming up at the end of January. This is the first time I’ll be attending, and I’m really looking forward to it!&lt;/p&gt;&lt;p&gt;There will be four concurrent presentations during most of the two main days of the conference (Jan 29th and 30th). Unfortunately, it’s a little challenging to visualize the schedule and pick which talk to attend using the &lt;a href=&#39;https://web.cvent.com/event/36ebe042-0113-44f1-8e36-b9bc5d0733bf/websitePage:34f3c2eb-9def-44a7-b324-f2d226e25011&#39;&gt;official conference agenda page&lt;/a&gt;.&lt;/p&gt;">
  <meta name="author" content="Dan LaBar"/><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "DL;DS",
    
    "url": "\/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "\/"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "\/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "\/post\/2020-01-20-schedule-for-rstudio-conf-2020l-talks\/",
          "name": "Schedule for rstudio conf(2020 l) talks"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : "Dan LaBar"
  },
  "headline": "Schedule for rstudio::conf(2020L) talks",
  "description" : "The RStudio conference is coming up at the end of January. This is the first time I’ll be attending, and I’m really looking forward to it!\nThere will be four concurrent presentations during most of the two main days of the conference (Jan 29th and 30th). Unfortunately, it’s a little challenging to visualize the schedule and pick which talk to attend using the official conference agenda page.\n",
  "inLanguage" : "en",
  "wordCount":  21808 ,
  "datePublished" : "2020-01-20T00:00:00",
  "dateModified" : "2020-01-20T00:00:00",
  "image" : "\/img\/embiggenData.png",
  "keywords" : [ "R, RStudio, conference, scraping" ],
  "mainEntityOfPage" : "\/post\/2020-01-20-schedule-for-rstudio-conf-2020l-talks\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "\/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "\/img\/embiggenData.png",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>

<meta property="og:title" content="Schedule for rstudio::conf(2020L) talks" />
<meta property="og:description" content="&lt;p&gt;The &lt;a href=&#39;https://rstudio.com/conference/&#39;&gt;RStudio conference&lt;/a&gt; is coming up at the end of January. This is the first time I’ll be attending, and I’m really looking forward to it!&lt;/p&gt;&lt;p&gt;There will be four concurrent presentations during most of the two main days of the conference (Jan 29th and 30th). Unfortunately, it’s a little challenging to visualize the schedule and pick which talk to attend using the &lt;a href=&#39;https://web.cvent.com/event/36ebe042-0113-44f1-8e36-b9bc5d0733bf/websitePage:34f3c2eb-9def-44a7-b324-f2d226e25011&#39;&gt;official conference agenda page&lt;/a&gt;.&lt;/p&gt;">
<meta property="og:image" content="/post/2020-01-20-schedule-for-rstudio-conf-2020l-talks/rstudio-conf.jpg" />
<meta property="og:url" content="/post/2020-01-20-schedule-for-rstudio-conf-2020l-talks/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="DL;DS" />

  <meta name="twitter:title" content="Schedule for rstudio::conf(2020L) talks" />
  <meta name="twitter:description" content="&lt;p&gt;The &lt;a href=&#39;https://rstudio.com/conference/&#39;&gt;RStudio conference&lt;/a&gt; is coming up at the end of January. This is the first time I’ll be attending, and I’m really looking forward to it!&lt;/p&gt;&lt;p&gt;There …">
  <meta name="twitter:image" content="/post/2020-01-20-schedule-for-rstudio-conf-2020l-talks/rstudio-conf.jpg" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@embiggenData" />
  <meta name="twitter:creator" content="@embiggenData" />
  <link href='/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.62.2" />
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="DL;DS"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><link rel="stylesheet" href="/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="/css/highlight.min.css" /><link rel="stylesheet" href="/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">


<style>
  .container {
    min-width: 1500px;
  }
</style>



  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">DL;DS</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/">Blog</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/page/about/index.html">About</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="/tags">Tags</a>
            </li>
          
        

        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="DL;DS" href="/">
            <img class="avatar-img" src="/img/embiggenData.png" alt="DL;DS" />
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>Schedule for rstudio::conf(2020L) talks</h1>
              
              
              
                
                  <h2 class="post-subheading">How to scrape the conference agenda page and visualize all the options</h2>
                
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on January 20, 2020
  
  
    &nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;103&nbsp;minutes
  
  
    &nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;21808&nbsp;words
  
  
    
      &nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Dan LaBar
    
  
  
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        
<script src="/./rmarkdown-libs/jquery/jquery.min.js"></script>
<script src="/./rmarkdown-libs/elevate-section-attrs/elevate-section-attrs.js"></script>
<script src="/./rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<link href="/./rmarkdown-libs/vis/vis.min.css" rel="stylesheet" />
<script src="/./rmarkdown-libs/vis/vis.min.js"></script>
<link href="/./rmarkdown-libs/timeline/timevis.css" rel="stylesheet" />
<script src="/./rmarkdown-libs/timevis-binding/timevis.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="/./rmarkdown-libs/bootstrap/css/bootstrap.min.css" rel="stylesheet" />
<script src="/./rmarkdown-libs/bootstrap/js/bootstrap.min.js"></script>
<script src="/./rmarkdown-libs/bootstrap/shim/html5shiv.min.js"></script>
<script src="/./rmarkdown-libs/bootstrap/shim/respond.min.js"></script>

<div id="TOC">
<ul>
<li><a href="#intro"><span class="toc-section-number">1</span> Intro</a></li>
<li><a href="#setup"><span class="toc-section-number">2</span> Setup</a>
<ul>
<li><a href="#packages"><span class="toc-section-number">2.1</span> Packages</a></li>
<li><a href="#page-rendering-tool"><span class="toc-section-number">2.2</span> Page rendering tool</a></li>
<li><a href="#check-robots.txt"><span class="toc-section-number">2.3</span> Check robots.txt</a></li>
</ul></li>
<li><a href="#scrape"><span class="toc-section-number">3</span> Scrape</a>
<ul>
<li><a href="#load-the-page"><span class="toc-section-number">3.1</span> Load the page</a></li>
<li><a href="#examine-the-content"><span class="toc-section-number">3.2</span> Examine the content</a></li>
<li><a href="#get-the-json"><span class="toc-section-number">3.3</span> Get the JSON</a>
<ul>
<li><a href="#session"><span class="toc-section-number">3.3.1</span> Session</a></li>
<li><a href="#speaker"><span class="toc-section-number">3.3.2</span> Speaker</a></li>
<li><a href="#category"><span class="toc-section-number">3.3.3</span> Category</a></li>
</ul></li>
</ul></li>
<li><a href="#prepare"><span class="toc-section-number">4</span> Prepare</a>
<ul>
<li><a href="#convert-datestimes"><span class="toc-section-number">4.1</span> Convert dates/times</a></li>
<li><a href="#add-category-name-and-style"><span class="toc-section-number">4.2</span> Add category name and style</a></li>
<li><a href="#split-out-list-columns"><span class="toc-section-number">4.3</span> Split out list columns</a></li>
<li><a href="#speaker-info-for-each-session"><span class="toc-section-number">4.4</span> Speaker info for each session</a></li>
<li><a href="#identify-workshops-vs-talks"><span class="toc-section-number">4.5</span> Identify workshops vs talks</a></li>
<li><a href="#format-talk-titles"><span class="toc-section-number">4.6</span> Format talk titles</a></li>
<li><a href="#find-overlapping-times"><span class="toc-section-number">4.7</span> Find overlapping times</a></li>
</ul></li>
<li><a href="#visualize"><span class="toc-section-number">5</span> Visualize</a>
<ul>
<li><a href="#take-1"><span class="toc-section-number">5.1</span> Take 1</a></li>
<li><a href="#take-2"><span class="toc-section-number">5.2</span> Take 2</a></li>
</ul></li>
<li><a href="#final-result"><span class="toc-section-number">6</span> Final result</a></li>
</ul>
</div>

<div id="intro" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Intro</h1>
<p>The <a href="https://rstudio.com/conference/">RStudio conference</a> (cleverly named <code>rstudio::conf</code>) is coming up at the end of
January. This is the first time I’ll be attending, and I’m really looking forward to it!</p>
<p>There will be four concurrent presentations during most of the two main days of the conference (Jan 29th and 30th).
Unfortunately, it’s a little challenging to visualize the schedule and pick which talk to attend using the
<a href="https://web.cvent.com/event/36ebe042-0113-44f1-8e36-b9bc5d0733bf/websitePage:34f3c2eb-9def-44a7-b324-f2d226e25011">official conference agenda page</a>.</p>
<p>Mara Averick (<a href="https://twitter.com/dataandme"><code>@dataandme</code></a>) tweeted about a
<a href="https://envelop.app/d/maraaverick/Av2QYN!TbmuIJTY4G07bILA">handy pdf</a> she created that lays out the schedule of talks.</p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">🎉 Stoked the <a href="https://twitter.com/hashtag/rstudioconf?src=hash&amp;ref_src=twsrc%5Etfw">#rstudioconf</a> schedule is out!<br>🗓 &quot;Agenda - rstudio::conf San Francisco&quot; <a href="https://t.co/4bIQgEpsmM">https://t.co/4bIQgEpsmM</a><br>Very unofficial version in a format I like looking at: <a href="https://t.co/SaTcFojUTe">https://t.co/SaTcFojUTe</a> <a href="https://t.co/KbKqU61Maz">pic.twitter.com/KbKqU61Maz</a></p>&mdash; Mara Averick (@dataandme) <a href="https://twitter.com/dataandme/status/1199327455405850625?ref_src=twsrc%5Etfw">November 26, 2019</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>I came across her tweet one 🐇 🕳 too late, however 🤦. Prior to that discovery I
had decided it would be “fun” to inspect the conference agenda page, see what it would take to scrape the details for
all the presentations, and try to display them in a nicer format.
<a href="https://www.youtube.com/embed/O6kRqnfsBEc?start=0&amp;end=48">Yada, yada, yada</a>, here’s a blog post for ya.</p>
<p>Before this thing is over, you’ll (hopefully) learn how
<strong>use R to create an interactive schedule of the conference talks</strong> that looks like this:
<img src="talkTimeline.png" alt="The finished product" /></p>
</div>
<div id="setup" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Setup</h1>
<div id="packages" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Packages</h2>
<p>Let’s start by loading some packages. I like to use the <a href="https://github.com/trinker/pacman"><code>pacman</code> package</a> from
Tyler Rinker (<a href="https://twitter.com/tylerrinker"><code>@tylerrinker</code></a>) to handle things. The <code>p_load</code> function takes
a vector of package names, installs them if necessary, and then loads them.</p>
<pre class="r"><code>pkgs &lt;- c(&quot;ggplot2&quot;, &quot;ggsci&quot;, &quot;jsonlite&quot;, &quot;magick&quot;, &quot;magrittr&quot;, &quot;rmarkdown&quot;,
          &quot;robotstxt&quot;, &quot;scales&quot;, &quot;splashr&quot;, &quot;timevis&quot;, &quot;urltools&quot;, &quot;data.table&quot;)

pacman::p_load(char=pkgs)</code></pre>
</div>
<div id="page-rendering-tool" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Page rendering tool</h2>
<p>We’ll use the <a href="https://gitlab.com/hrbrmstr/splashr"><code>splashr</code> package</a> from Bob Rudis
(<a href="https://twitter.com/hrbrmstr"><code>@hrbrmstr</code></a>) to load the page and grab the content we need, all from the comfort of R.</p>
<p>Why do we need this? As usual the great R community 🙌 has developed many
<a href="https://cran.r-project.org/web/views/WebTechnologies.html">packages for web-related tasks</a>. The
<a href="https://github.com/tidyverse/rvest"><code>rvest</code> package</a> is one that can be very useful in certain situations. But many
times our old pal Javascript is invited to the party and
<a href="https://datascienceplus.com/scraping-javascript-rendered-web-content-using-r/">adds some complications</a> that require a
tool like <a href="https://splash.readthedocs.io/en/stable/">Splash</a> that can render it. The <code>splashr</code> package looks well
supported and it’s relatively new so I wanted to give it a spin.</p>
<p>You can read through the <a href="https://cran.r-project.org/web/packages/splashr/vignettes/intro_to_splashr.html">splashr intro vignette</a>,
but it’s pretty straightforward to get started. Just <a href="https://docs.docker.com/install">install docker</a> if you haven’t
already and then run <code>install_splash()</code> in R.</p>
<p>Now let’s fire up a Splash docker container, which will be the thing that does the thing (i.e. scrape the page).</p>
<pre class="r"><code>spCon &lt;- start_splash()</code></pre>
<pre><code>## Detected API version &#39;1.40&#39; is above max version &#39;1.39&#39;; downgrading</code></pre>
<pre><code>## Error pulling image from DockerHub.</code></pre>
<p><br>
I didn’t have problems running this initially, but for whatever reason when I went to make this post it started
complaining a little about the (docker?) API version. Hopefully it works for those of you following along at home! You
can check the status with the following function.</p>
<pre class="r"><code>splash_active()</code></pre>
<pre><code>## Status of splash instance on [http://localhost:8050]: ok. Max RSS: 1,026 Mb</code></pre>
<pre><code>## [1] TRUE</code></pre>
</div>
<div id="check-robots.txt" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Check robots.txt</h2>
<p>Now that we’ve made a splash 🙄, let’s specify the URL of the conference agenda page that we’ll be
scraping and check the page’s <a href="https://en.wikipedia.org/wiki/Robots_exclusion_standard">robots.txt</a>. Use the handy
and aptly named <a href="https://github.com/ropensci/robotstxt"><code>robotstxt</code> package</a> from Peter Meissner
(<a href="https://twitter.com/peterlovesdata"><code>@peterlovesdata</code></a>) to make sure it’s ok to scrape the event page.</p>
<pre class="r"><code>## Page to scrape
urlConf &lt;-
  &quot;https://web.cvent.com/event/36ebe042-0113-44f1-8e36-b9bc5d0733bf/websitePage:34f3c2eb-9def-44a7-b324-f2d226e25011&quot;

## Parse the domain
urlDomain &lt;- urltools::domain(urlConf)

## Get the robots.txt file
rt &lt;- get_robotstxt(urlDomain)

## Check robots.txt
pa &lt;- paths_allowed(domain=urlDomain)

rt</code></pre>
<pre><code>## # robots.txt for https://web.cvent.com
## # : robots.txt,v 1.00 2017/11/28 
##     User-agent: Wget
##     Disallow:/
##     User-agent: Wget/1.9
##     Disallow:/
##     User-agent: Wget/1.6
##     Disallow:/
##     User-agent: Wget/1.5.3
##     Disallow:/
##     User-agent: AhrefsBot
##     Disallow: / 
##     Sitemap: https://web.cvent.com/sitemap?environment=P2</code></pre>
<pre class="r"><code>pa</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>The output of <code>paths_allowed</code> is TRUE, so we’ve got the “all clear” to scrape this thing. Responsibly, of course.</p>
</div>
</div>
<div id="scrape" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Scrape</h1>
<div id="load-the-page" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Load the page</h2>
<p>We can fetch the page and all its accouterments using the <code>splashr::render_json</code> function. I initially set a <code>wait</code>
value of 3 seconds, which apparently was not enough time for the page to load on my machine; YMMV. If you want to see
an image of the rendered page (hopefully after it’s fully loaded), you can set the PNG argument to <code>TRUE</code> and then
display it with <code>magick::image_read</code>.</p>
<pre class="r"><code>## Load the page and take a screenshot
pg &lt;- render_json(url=urlConf, wait=5, png=TRUE, response_body=TRUE)
#pg$html

## Show the screenshot
#render_png(url=urlConf, wait=3) ## Alt method, if you just want the screenshot and nothing else
pgPNG &lt;- image_read(base64_dec(pg$png))
pgPNG</code></pre>
<p><img src="/./post/2020-01-20-schedule-for-rstudio-conf-2020l-talks/index.en_files/figure-html/screen-scrape-1.png" width="512" /></p>
</div>
<div id="examine-the-content" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Examine the content</h2>
<p>We’ve got everything set up, so now we need to become familiar with the structure and content of the page we’re
scraping. (IRL, you’d want to <em>start</em> by investigating the page and <em>then</em> determine which tools to use to scrape it,
but as your cheesy cooking show host I’ve already pre-baked that part for this blog post.) Load the
<a href="https://web.cvent.com/event/36ebe042-0113-44f1-8e36-b9bc5d0733bf/websitePage:34f3c2eb-9def-44a7-b324-f2d226e25011" target="_blank">conference agenda page</a> in your desktop browser, open the
<a href="https://en.wikipedia.org/wiki/Web_development_tools">web development tools</a>, and go to the network tab. (The keyboard
shortcut to the network tab in Firefox is <kbd>⌘</kbd>+<kbd>⌥</kbd>+<kbd>E</kbd> on macOS and
<kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>E</kbd> in Windows/Linux.) You’ll likely want to clear the existing results and
reload the page.</p>
<p>We could try to scrape the rendered HTML, but it seems that the content for each session is only revealed after clicking
on the session. We could probably do that with Splash, but there is an easier option. I had a hunch that the
conference session details would be stored in a JSON file, and that turned out to be correct. Filter (by selecting XHR)
or sort the network results by type and look for a JSON file with “products” in the name. Check the response tab, which
contains the formatted contents of the file.</p>
<br>
<img style="width:100%;" src="sessionProducts.png" alt="Screenshot of browser developer tools" />
<br>
<div style="margin:auto; width:480px;">
<a href="https://giphy.com/gifs/seinfeld-giddyup-rPO52Fc8gSwzS">
<img style="width:100%;" src="giddyup.gif" alt="Giddy up!" />
<figcaption>
<img style="width:120px; float:right; padding-top:5px;" src="giphy.png" alt="Giphy logo" />
</figcaption>
<p></a></p>
</div>
<p><br></p>
</div>
<div id="get-the-json" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Get the JSON</h2>
<p>If you’re just tuning in, we know the JSON with the conference session details is out there 👽. Our
friend <code>splashr</code> saved an <a href="https://en.wikipedia.org/wiki/HAR_(file_format)">HTTP archive (HAR)</a> for us
<a href="#load-the-page">earlier</a>, so we can grab it from that. But first we need to find it. Take a look at the HAR object.</p>
<pre class="r"><code>## Get the HTTP ARchive (HAR) file that contains a list of page resources

## Alt method if you just want the HAR and nothing else:
#har &lt;- render_har(url=url, wait=3, response_body=TRUE)

har &lt;- pg$har
har</code></pre>
<pre><code>## --------HAR VERSION-------- 
## HAR specification version: 1.2 
## --------HAR CREATOR-------- 
## Created by: Splash 
## version: 3.4 
## --------HAR BROWSER-------- 
## Browser: QWebKit 
## version: 602.1 
## --------HAR PAGES-------- 
## Page id: 1 , Page title: Agenda - rstudio::conf San Francisco 
## Page id: 2 , Page title:  
## --------HAR ENTRIES-------- 
## Number of entries: 293 
## REQUESTS: 
## Page: 1 
## Number of entries: 38 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/css/styles.prod.... 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/runtime.prod._v5... 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/vendor.prod._v5.... 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/styles.prod._v5.... 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/main.prod._v5.a7... 
##      ........ 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/fonts/Lato-Bold_... 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/fonts/lato-v13-l... 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/fonts/Lato-Black... 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/fonts/Lato-Black... 
##   -  https://web.cvent.com/event_guest/v1/websiteContent/36ebe042-0113-44f1-8e... 
## Page: 2 
## Number of entries: 255 
##   -  https://web.cvent.com/event/36ebe042-0113-44f1-8e36-b9bc5d0733bf/websiteP... 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/1.prod._v5.754ca... 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/12.prod._v5.672e... 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/16.prod._v5.9d01... 
##   -  https://www.cvent-assets.com/event-guestside-site/assets/92.prod._v5.3948... 
##      ........ 
##   -  https://custom.cvent.com/127B71FE97E440DFB772841518587A73/files/event/36e... 
##   -  https://custom.cvent.com/127B71FE97E440DFB772841518587A73/files/event/36e... 
##   -  https://custom.cvent.com/127B71FE97E440DFB772841518587A73/files/event/36e... 
##   -  https://custom.cvent.com/127B71FE97E440DFB772841518587A73/files/event/36e... 
##   -  https://custom.cvent.com/127B71FE97E440DFB772841518587A73/files/event/36e...</code></pre>
<p><br>
Gowrgeous, isn’t it? Before I start to get emotional or even a little
<a href="(https://www.youtube.com/embed/oiJkANps0Qw?start=144&amp;end=165)">verklempt</a>, let’s let the computers tawlk amongst
themselves and find the JSON file fowr us.</p>
<div style="margin:auto; width:480px;">
<a href="https://giphy.com/gifs/coffee-talk-verklempt-linda-richman-l2SpQRuCQzY1RXHqM">
<img style="width:100%;" src="talkamongst.gif" alt="Talk amongst yourselves!" />
<figcaption>
<img style="width:120px; float:right; padding-top:5px;" src="giphy.png" alt="Giphy logo" />
</figcaption>
<p></a></p>
</div>
<p><br></p>
<div id="session" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Session</h3>
<p>The chunk of R code below <del>loops</del> lapplys through all the entries in the HAR log (<code>har$log$entries</code>), looks for JSON
files (<code>x$response$content$mimeType %like% "json"</code>) that contain “products” in the name
(<code>x$response$url %like% "products"</code>), and returns the indices for those matching files (<code>which</code>).</p>
<pre class="r"><code>## Determine the index for the JSON file containing the conference session details
sessionIdx &lt;-
  lapply(har$log$entries, function(x)
  x$response$content$mimeType %like% &quot;json&quot; &amp; x$response$url %like% &quot;products&quot;
) %&gt;%
  unlist %&gt;%
  which

sessionIdx</code></pre>
<pre><code>## [1] 45</code></pre>
<p><br>
Now we can get the text from the response for item 45 (the products JSON file) from the HAR. Let’s also use
the awesome <a href="https://rdatatable.gitlab.io/data.table/"><code>data.table</code> package</a> created by Matt Dowle
(<a href="https://twitter.com/mattdowle"><code>@mattdowle</code></a>) to reformat the JSON into a table. There are a few naughty nested
JSON elements that don’t add much value (<code>fees</code> and <code>associatedRegistrationTypes</code>) that I’m removing here.</p>
<pre class="r"><code>## Get the JSON
sessionJSON &lt;-
  har_entries(har)[[sessionIdx[1]]] %&gt;% 
  get_response_body(&quot;text&quot;)

## Convert from JSON to data.table
session &lt;-
  fromJSON(sessionJSON)$sessionProducts %&gt;%
  lapply(function(x) {
    #as.data.table(x[!lapply(x, length) &gt; 1L]) ## Drop any columns with more than one row per session
    as.data.table(x[!names(x) %chin% c(&quot;fees&quot;, &quot;associatedRegistrationTypes&quot;)]) ## Drop specific columns
  }) %&gt;%
  rbindlist(fill=TRUE)</code></pre>
<p>Let’s look at the structure of the resulting table.</p>
<pre class="r"><code>## Print the table; takes up too much space for this blog
#rmarkdown::paged_table(session)

## Examine the structure of a row in the table
exampleId &lt;- &quot;d8d901d9-bdb6-4392-83a9-3ad5addbbf53&quot;
str(session[id==exampleId])</code></pre>
<pre><code>## Classes &#39;data.table&#39; and &#39;data.frame&#39;:   2 obs. of  23 variables:
##  $ categoryId              : chr  &quot;c32f17f6-2464-476b-859b-d8ab4d26556b&quot; &quot;c32f17f6-2464-476b-859b-d8ab4d26556b&quot;
##  $ waitlistCapacityId      : chr  &quot;d8d901d9-bdb6-4392-83a9-3ad5addbbf53_waitlist&quot; &quot;d8d901d9-bdb6-4392-83a9-3ad5addbbf53_waitlist&quot;
##  $ startTime               : chr  &quot;2020-01-29T18:00:00.000Z&quot; &quot;2020-01-29T18:00:00.000Z&quot;
##  $ endTime                 : chr  &quot;2020-01-29T19:00:00.000Z&quot; &quot;2020-01-29T19:00:00.000Z&quot;
##  $ isOpenForRegistration   : logi  TRUE TRUE
##  $ isIncludedSession       : logi  FALSE FALSE
##  $ isWaitlistEnabled       : logi  FALSE FALSE
##  $ sessionCustomFieldValues:List of 2
##   ..$ : NULL
##   ..$ : NULL
##  $ richTextDescription     : chr  &quot;{\&quot;format\&quot;:\&quot;draftjs-nucleus\&quot;,\&quot;version\&quot;:1,\&quot;content\&quot;:{\&quot;blocks\&quot;:[{\&quot;key\&quot;:\&quot;bges0\&quot;,\&quot;text\&quot;:\&quot;Recent pro&quot;| __truncated__ &quot;{\&quot;format\&quot;:\&quot;draftjs-nucleus\&quot;,\&quot;version\&quot;:1,\&quot;content\&quot;:{\&quot;blocks\&quot;:[{\&quot;key\&quot;:\&quot;bges0\&quot;,\&quot;text\&quot;:\&quot;Recent pro&quot;| __truncated__
##  $ displayPriority         : int  0 0
##  $ showOnAgenda            : logi  TRUE TRUE
##  $ speakerIds              :List of 2
##   ..$ :List of 3
##   .. ..$ speakerId        : chr &quot;310ea87b-1917-4252-a3f0-10c737b5a73a&quot;
##   .. ..$ speakerCategoryId: chr &quot;86502b84-9704-4416-baf2-ec9edc15fd4f&quot;
##   .. ..$ sessionId        : chr &quot;d8d901d9-bdb6-4392-83a9-3ad5addbbf53&quot;
##   ..$ :List of 3
##   .. ..$ speakerId        : chr &quot;3cb4488b-81dd-4ad3-b94a-90987821825c&quot;
##   .. ..$ speakerCategoryId: chr &quot;86502b84-9704-4416-baf2-ec9edc15fd4f&quot;
##   .. ..$ sessionId        : chr &quot;d8d901d9-bdb6-4392-83a9-3ad5addbbf53&quot;
##  $ code                    : chr  &quot;&quot; &quot;&quot;
##  $ description             : chr  &quot;&lt;div class=\&quot;ag87-crtemvc-hsbk\&quot;&gt;&lt;div class=css-zuif4x&gt;&lt;p class=\&quot;carina-rte-public-DraftStyleDefault-block\&quot;&gt;&lt;&quot;| __truncated__ &quot;&lt;div class=\&quot;ag87-crtemvc-hsbk\&quot;&gt;&lt;div class=css-zuif4x&gt;&lt;p class=\&quot;carina-rte-public-DraftStyleDefault-block\&quot;&gt;&lt;&quot;| __truncated__
##  $ id                      : chr  &quot;d8d901d9-bdb6-4392-83a9-3ad5addbbf53&quot; &quot;d8d901d9-bdb6-4392-83a9-3ad5addbbf53&quot;
##  $ capacityId              : chr  &quot;d8d901d9-bdb6-4392-83a9-3ad5addbbf53&quot; &quot;d8d901d9-bdb6-4392-83a9-3ad5addbbf53&quot;
##  $ name                    : chr  &quot;Data, visualization, and designing with AI&quot; &quot;Data, visualization, and designing with AI&quot;
##  $ status                  : int  2 2
##  $ type                    : chr  &quot;Session&quot; &quot;Session&quot;
##  $ defaultFeeId            : chr  &quot;00000000-0000-0000-0000-000000000000&quot; &quot;00000000-0000-0000-0000-000000000000&quot;
##  $ closedReasonType        : chr  &quot;NotClosed&quot; &quot;NotClosed&quot;
##  $ locationName            : chr  &quot;Room 2&quot; &quot;Room 2&quot;
##  $ locationCode            : chr  &quot;Room 21578074754834&quot; &quot;Room 21578074754834&quot;
##  - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt;</code></pre>
<p>Still a bit of an eyesore, but it’s in a tabluar and mostly-tidy format, so we can work with it.</p>
</div>
<div id="speaker" class="section level3" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> Speaker</h3>
<p>The speaker name, bio, and other info is stored in a separate JSON file. The code below finds and retrieves the
file in a similar fashion as the <a href="#session">session info</a>.</p>
<pre class="r"><code>speakerIdx &lt;-
  lapply(har$log$entries, function(x)
    x$response$content$mimeType %like% &quot;json&quot; &amp; x$response$url %like% &quot;Sessions&quot;
  ) %&gt;%
  unlist %&gt;%
  which

## Get the JSON
speakerJSON &lt;-
  har_entries(har)[[speakerIdx[1]]] %&gt;% 
  get_response_body(&quot;text&quot;)

## Convert from JSON to data.table
speaker &lt;-
  fromJSON(speakerJSON)$speakerInfoSnapshot$speaker %&gt;%
  lapply(as.data.table) %&gt;%
  rbindlist(fill=TRUE)

## Print the table; takes up too much space for this blog
#rmarkdown::paged_table(speaker)

## Examine the structure of a row in the table
str(speaker[1])</code></pre>
<pre><code>## Classes &#39;data.table&#39; and &#39;data.frame&#39;:   1 obs. of  17 variables:
##  $ id                  : chr &quot;78ff1c9c-02da-461b-a661-155b4ec3d15a&quot;
##  $ categoryId          : chr &quot;86502b84-9704-4416-baf2-ec9edc15fd4f&quot;
##  $ firstName           : chr &quot;Ian&quot;
##  $ lastName            : chr &quot;Lyttle&quot;
##  $ prefix              : chr &quot;&quot;
##  $ company             : chr &quot;Schneider Electric&quot;
##  $ title               : chr &quot;&quot;
##  $ biography           : chr &quot;Ian Lyttle works at Schneider Electric as a data scientist, with a focus on visualization. He is an enthusiasti&quot;| __truncated__
##  $ designation         : chr &quot;&quot;
##  $ displayOnWebsite    : logi TRUE
##  $ facebookUrl         : chr &quot;&quot;
##  $ twitterUrl          : chr &quot;https://twitter.com/ijlyttle&quot;
##  $ linkedInUrl         : chr &quot;https://www.linkedin.com/in/ian-lyttle-a4a02917/&quot;
##  $ order               : int 81
##  $ profileImageFileName: chr &quot;lyttle2017lores1567810718091.png&quot;
##  $ profileImageUri     : chr &quot;https://custom.cvent.com/127B71FE97E440DFB772841518587A73/files/event/36ebe042011344f18e36b9bc5d0733bf/lyttle20&quot;| __truncated__
##  $ websites            :List of 1
##   ..$ : NULL
##  - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt;</code></pre>
</div>
<div id="category" class="section level3" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> Category</h3>
<p>We need one final JSON file containing the category info for the sessions.</p>
<pre class="r"><code>categoryIdx &lt;-
  lapply(har$log$entries, function(x)
    x$response$content$mimeType %like% &quot;json&quot; &amp; x$response$url %like% &quot;account&quot;
  ) %&gt;%
  unlist %&gt;%
  which

## Get the JSON
categoryJSON &lt;-
  har_entries(har)[[categoryIdx[1]]] %&gt;% 
  get_response_body(&quot;text&quot;)

## Convert from JSON to data.table
category &lt;-
  fromJSON(categoryJSON)$sessionCategories %&gt;%
  lapply(as.data.table) %&gt;%
  rbindlist(fill=TRUE)

## Print the table; takes up too much space for this blog
#rmarkdown::paged_table(category)

## Examine the structure of a row in the table
str(category[3])</code></pre>
<pre><code>## Classes &#39;data.table&#39; and &#39;data.frame&#39;:   1 obs. of  3 variables:
##  $ id         : chr &quot;9541ec43-0d38-4c2a-a1d3-765a3e1d1e01&quot;
##  $ name       : chr &quot;Learning and Using R&quot;
##  $ description: chr &quot;&quot;
##  - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt;</code></pre>
</div>
</div>
</div>
<div id="prepare" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Prepare</h1>
<p>Ok, that was a decent amount of work, but surely <em>now</em> we’re ready to do something more exciting, right? Right?
🦗</p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">In Data Science, 80% of time spent prepare data, 20% of time spent complain about need for prepare data.</p>&mdash; Big Data Borat (@BigDataBorat) <a href="https://twitter.com/BigDataBorat/status/306596352991830016?ref_src=twsrc%5Etfw">February 27, 2013</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<div id="convert-datestimes" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Convert dates/times</h2>
<p>We want to know the dates and times of the rstudio::conf sessions, but they’re currently stored as text in the tables
we’ve scraped. Since the event is in San Fran, we also want to display the time using the US/Pacific time zone rather
than UTC. There are multiple date/time columns, so we can loop through them and apply the same transformation to each.</p>
<p>The code below converts all columns with “time” in the name. I use <code>data.table</code> all the time, but it took a few
trips to Google and re-finding <a href="https://stackoverflow.com/a/16846530/1344789">this Stackoverflow answer</a> before I
eventually remembered the syntax for applying a function to each column in a table. Also, we could probably use
<a href="https://lubridate.tidyverse.org/"><code>lubridate</code></a> to make the date/time conversion a little easier, but I’m feeling
complicated.</p>
<div style="margin:auto; width:480px;">
<a href="https://media.giphy.com/media/abJQukJ1NIAHS/giphy.gif">
<img style="width:100%;" src="kenjeonghaveyoumetme.gif" alt="Have you met me?!" />
<figcaption>
<img style="width:120px; float:right; padding-top:5px;" src="giphy.png" alt="Giphy logo" />
</figcaption>
<p></a></p>
</div>
<p><br></p>
<pre class="r"><code>## Function to convert a string to POSIXct and change the timezone format
dateTimeConvert &lt;- function(x, fmt, tzOrig, tzNew) {
  
  .POSIXct(as.integer(as.POSIXct(x, format=fmt, tz=tzOrig)), tz=tzNew)
  
}

cols &lt;- names(session)[names(session) %like% &quot;[Tt]ime&quot;]
cols</code></pre>
<pre><code>## [1] &quot;startTime&quot; &quot;endTime&quot;</code></pre>
<pre class="r"><code>## Convert timestamps from UTC to Pacific
for(n in cols)
  set(session, j=n, value=dateTimeConvert(session[[n]], &quot;%FT%T&quot;, &quot;UTC&quot;, &quot;US/Pacific&quot;))

## Examine the structure of the date/time columns
str(session[, mget(cols)])</code></pre>
<pre><code>## Classes &#39;data.table&#39; and &#39;data.frame&#39;:   137 obs. of  2 variables:
##  $ startTime: POSIXct, format: &quot;2020-01-27 09:00:00&quot; &quot;2020-01-27 09:00:00&quot; ...
##  $ endTime  : POSIXct, format: &quot;2020-01-28 17:00:00&quot; &quot;2020-01-28 17:00:00&quot; ...
##  - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt;</code></pre>
</div>
<div id="add-category-name-and-style" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Add category name and style</h2>
<p><a href="#category">A few steps ago</a>, we grabbed a JSON file containing the session categories. In
<a href="#visualize">a few steps from now</a>, we’ll color code each session/talk based on the category. Here is an example:</p>
<p>
<div style="width: 120px; height: 30px; line-height: 30px; text-align: center; color: white; background-color: rgba(54, 3, 53, 0.7); border-color: rgb(54, 3, 53)">
R: Then and Now
</div>
</p>
<p>Let’s prep for that by creating a color palette and assigning a color to each session. The
<a href="https://github.com/nanxstats/ggsci"><code>ggsci</code> package</a> from Nan Xiao (<a href="https://twitter.com/nanxstats"><code>@nanxstats</code></a>) et
al. has some nice color palettes. The Springfield collection from the Simpsons™ palette has a max of 16 colors,
but it turns out there are 34 categories in the rstudio::conf data.</p>
<p>
<div style="margin:auto; width:480px;">
<a href="https://media.giphy.com/media/l2JeccUjGIeaxT9du/giphy.gif">
<img style="width:100%;" src="whatdoido.gif" alt="What do I do?! What do I do?!" />
<figcaption>
<img style="width:120px; float:right; padding-top:5px;" src="giphy.png" alt="Giphy logo" />
</figcaption>
<p></a></p>
</div>
</p>
<p><br>
Not to worry, we can use <code>grDevices::colorRampPalette</code> to interpolate as many colors as we need.</p>
<pre class="r"><code>nColorsMax &lt;- 16

## How many colors do we need?
nColors &lt;- nrow(category)

## Create the palette
styleColors &lt;- colorRampPalette(ggsci::pal_simpsons(&quot;springfield&quot;)(min(c(nColors, nColorsMax))))(nColors)

## Examine what we&#39;ve got
scales::show_col(styleColors)</code></pre>
<p><img src="/./post/2020-01-20-schedule-for-rstudio-conf-2020l-talks/index.en_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>That’ll do. Now we need to create a little <a href="https://en.wikipedia.org/wiki/Cascading_Style_Sheets">CSS</a> to style the
colors for the border, background, and text of the session info boxes. For the border we can use the colors from the
palette we created. To differentiate it from the border color, let’s set the transparency of the background color to
70%. One quick hack–that <a href="https://caniuse.com/#feat=css-rrggbbaa">may not work in all browsers</a>–is to add the
transparency (alpha) value at the end of the normal hex color value. For example,
<span style="color:white; background-color:rgb(54, 3, 53)">#360335</span> would become
<span style="color:white; background-color:rgb(54, 3, 53, 0.7)">#360335<span style="text-decoration: underline;">B3</span></span>.
(<code>B3</code> is the hex representation for 70%.) For the text let’s go with white, since most of the palette colors are on the
darker side.</p>
<p>The code below adds a style column to the category table that specifies the CSS to use for each category. Then it adds
the category name and style columns from the category info table to the session table, joining on the id columns. (Here
and elsewhere throughout the post I am using the <code>data.table</code> package to wrangle data. Check the
<a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html">intro vignette</a> if you’re
unfamiliar with the syntax.)</p>
<pre class="r"><code>alpha &lt;- 0.7
alphaHex &lt;- 
  median(c(alpha, 0, 1)) * 256 %&gt;% ## Make sure alpha is between 0 and 1, and multiply by 256
  as.integer %&gt;% ## Convert to a whole number
  as.hexmode ## Convert to hexadecimal

## Add the CSS style column
category[, style:=sprintf(
  &quot;color: white; background-color: %1$s%2$s; border-color: %1$s;&quot;, styleColors, alphaHex)]

## Add the category name and style to the session table
session[category, `:=`(categoryName=i.name, style=style), on=c(categoryId=&quot;id&quot;)]</code></pre>
</div>
<div id="split-out-list-columns" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Split out list columns</h2>
<p>Our JSON files had some nesting that we’ve so far ignored. Let’s rectify that by splitting out those list columns
(which currently have multiple rows per row in the main table) into their own tables.</p>
<pre class="r"><code>## This table links the session to the speaker(s)
sessionSpeakerId &lt;-
  session[, .(rbindlist(speakerIds))] %&gt;%
  unique ## Remove duplicate rows

## Print a few rows
#rmarkdown::paged_table(sessionSpeakerId[1:5])

## Examine the structure 
#str(sessionSpeakerId)

## Column names
names(sessionSpeakerId)</code></pre>
<pre><code>## [1] &quot;speakerId&quot;         &quot;speakerCategoryId&quot; &quot;sessionId&quot;</code></pre>
<pre class="r"><code>## This table contains links to social media and other types of pages for the speakers
speakerLink &lt;-
  speaker[, .(rbindlist(websites))] %&gt;%
  unique ## Remove duplicate rows

## Print a few rows
#rmarkdown::paged_table(speakerLink[1:5])

## Examine the structure
#str(speakerLink)

## Column names
names(speakerLink)</code></pre>
<pre><code>## [1] &quot;id&quot;                   &quot;relatedUrl&quot;           &quot;isDisplay&quot;           
## [4] &quot;relatedUrlName&quot;       &quot;relatedUrlCategoryId&quot; &quot;speakerId&quot;</code></pre>
</div>
<div id="speaker-info-for-each-session" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Speaker info for each session</h2>
<p>We will <a href="#take-2">eventually</a> create a bunch of boxes containing the session name, but to be more informative we’ll want
to add popup messages that provide more details for each session, including info about the speaker. The code below
contains a function that combines the company and title for each speaker, handling cases where one or the other or both
are missing.</p>
<pre class="r"><code>## Format the speaker&#39;s combined title and company
titleCompany &lt;- function(company, title) {
  
  ## Replace semicolon with slash in title, since we&#39;ll use semicolon to delimit multiple speakers later
  title &lt;- gsub(&quot;; &quot;, &quot; / &quot;, title)
  
  ## Convert NA to empty string
  if(is.na(title)) title &lt;- &quot;&quot;
  if(is.na(company)) company &lt;- &quot;&quot;
  
  ## Check for empty string
  valT &lt;- title==&quot;&quot;
  valC &lt;- company==&quot;&quot;
  
  ## If both are empty, return empty
  if(all(c(valT, valC))) return(&quot;&quot;)
  
  ## Combine the company and title
  val &lt;-
    if(any(c(valT, valC))) paste0(title, company) else
      paste(c(title, company), collapse=&quot;, &quot;)
  
  ## Wrap in parenthesis
  return(sprintf(&quot;(%s)&quot;, val))
}</code></pre>
<p>The <code>sessionSpeakerId</code> table that we <a href="#split-out-list-columns">split out in the previously</a> lets us relate the speaker
to the session. Let’s use it now to merge those two tables. While we’re at it, we’ll use that speaker title/company
function to format the speaker info. If there are multiple speakers per session, we’ll collapse it into a single text
value separated by a semicolon.</p>
<pre class="r"><code>## Add the session and category identifiers to the speaker table
## The result contains one row per combination of session and speaker
sessionSpeaker &lt;- merge(sessionSpeakerId, speaker, by.x=&quot;speakerId&quot;, by.y=&quot;id&quot;)

sessionSpeakerInfo &lt;-
  ## Select the columns we need
  sessionSpeaker[, .(sessionId, speakerId, firstName, lastName, title, company)] %&gt;%
  
  ## Remove duplicates
  unique %&gt;%
  
  ## Format the speaker info
  .[, speakerInfo:=trimws(paste(firstName, lastName, titleCompany(title, company))), by=.(sessionId, speakerId)] %&gt;%
  
  ## Collapse multiple speakers into a single semicolon-delimited value
  .[, .(speakerInfo=paste(unique(speakerInfo), collapse=&quot;; &quot;)), by=.(sessionId)]

sessionSpeakerInfo[, .(speakerInfo)]</code></pre>
<pre><code>##                                                                                   speakerInfo
##   1:                                      Andrew Mangano (Salesforce, Data Intelligence Lead)
##   2:                                          Yim Register (RStudio/University of Washington)
##   3:                                    Jared Lander (Lander Analytics, Chief Data Scientist)
##   4:                                          Jonathan McPherson (RStudio, Software Engineer)
##   5:                                                   Maria Ortiz Mancera (CONABIO, Advisor)
##  ---                                                                                         
## 119:                                Dani Chu (NHL Seattle, Quantitative Analyst - Statistics)
## 120:                      Tyson Barrett (Utah State University, Research Assistant Professor)
## 121:                                                  David Smith (Microsoft, Cloud Advocate)
## 122:                         BenJoaquin Gouverneur (Plenty Unlimited, Inc., Manager, Datalab)
## 123: Travis Gerke (Moffitt Cancer Center, Scientific Director of Collaborative Data Services)</code></pre>
<p>Now we can add the speaker info to the session table.</p>
<pre class="r"><code>session[sessionSpeakerInfo, speakerInfo:=speakerInfo, on=c(id=&quot;sessionId&quot;)]
names(session)</code></pre>
<pre><code>##  [1] &quot;categoryId&quot;               &quot;waitlistCapacityId&quot;      
##  [3] &quot;startTime&quot;                &quot;endTime&quot;                 
##  [5] &quot;isOpenForRegistration&quot;    &quot;isIncludedSession&quot;       
##  [7] &quot;isWaitlistEnabled&quot;        &quot;sessionCustomFieldValues&quot;
##  [9] &quot;richTextDescription&quot;      &quot;displayPriority&quot;         
## [11] &quot;showOnAgenda&quot;             &quot;speakerIds&quot;              
## [13] &quot;code&quot;                     &quot;description&quot;             
## [15] &quot;id&quot;                       &quot;capacityId&quot;              
## [17] &quot;name&quot;                     &quot;status&quot;                  
## [19] &quot;type&quot;                     &quot;defaultFeeId&quot;            
## [21] &quot;closedReasonType&quot;         &quot;locationName&quot;            
## [23] &quot;locationCode&quot;             &quot;categoryName&quot;            
## [25] &quot;style&quot;                    &quot;speakerInfo&quot;</code></pre>
</div>
<div id="identify-workshops-vs-talks" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> Identify workshops vs talks</h2>
<p>Conference attenders can sign up for two-day workshops on Jan 27th and 28th. For the purposes of this post though, we
only care about the talks on the 29th and 30th. (Remember the <a href="#intro">intro</a>, from like 30 minutes ago? We’re trying
to make a friendlier display of the schedules so we can choose which of the four concurrent sessions to attend.)</p>
<p>How can we classify the session info into “workshop” vs “talk”, using only the text descriptions?! This is a job for
<a href="https://github.com/google-research/bert"><code>BERT-Large</code></a>! Or–if you fancy the uncased case–<code>bert-large</code>.</p>
<p>Sorry for the anti-climax, but it turns out that the workshops don’t have room location information while
the talks do; no need for any fancy NLP here. Also, we could have just filtered by date 😉. But
seriously, someone needs to create a state-of-the-art-for-this-nanosecond transformer called SUPER-GROVER™.</p>
<p><a href="https://imgflip.com/i/3lutqq"><img src="https://i.imgflip.com/3lutqq.jpg" title="made at imgflip.com"/></a></p>
<p>Using that breakthrough insight, let’s subset the session info to only those rows that have location data. The code
below also grabs the global session identifier, start and end times, class name and description, location, and speaker
info. We’ll use these columns for our final output. We’ll also do one last check for duplicate rows.</p>
<pre class="r"><code>## Subset the talks, select the relevant columns, and de-duplicate
talks &lt;-
  session[!is.na(locationName), .(
    id, startTime, endTime, categoryName, name, description, locationName, speakerInfo, style)] %&gt;%
  unique

## Make sure there aren&#39;t any dupes left
talksCheckDupes &lt;- talks[, .N, by=id][N&gt;1]
if(nrow(talksCheckDupes) &gt; 0) warning(&quot;There are multiple rows with the same identifier!&quot;)</code></pre>
</div>
<div id="format-talk-titles" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Format talk titles</h2>
<p>Judging from the length of the talk titles (and this blog post), the R community can be pretty wordy at times! Congrats
to “The good, the bad and the ugly: What I learned while consulting across the business as a data scient” for being the longest title. It looks
like they actually ✂ off titles at 100 characters.</p>
<pre class="r"><code>ggplot(talks[, .(nameLength=nchar(name))], aes(x=nameLength)) +
  geom_histogram(binwidth=2) +
  labs(x=&quot;Number of characters in session title&quot;, y=&quot;Count&quot;) +
  theme_minimal(base_size=18)</code></pre>
<p><img src="/./post/2020-01-20-schedule-for-rstudio-conf-2020l-talks/index.en_files/figure-html/unnamed-chunk-21-1.png" width="100%" /></p>
<p>While informative, the long titles are a challenge to display compactly. For the schedule visualization tool we’d like
to reshape the text a bit, breaking long titles into multiple rows. We can use <code>strwrap</code> to split the text at word
boundaries, inserting a line break after 20 characters (a value chosen after trial and error).</p>
<pre class="r"><code>maxWidth &lt;- 20

#talks[, nameWrap:=substr(paste(strwrap(name, width=maxWidth), collapse=&quot;\n&quot;), 0, maxWidth*3)]
## Break it
talks[, nameWrap:=
        name %&gt;% ## Original session name
        strwrap(width=maxWidth) %&gt;% ## Wrap it
        .[1:4] %&gt;% ## Allow up to 4 rows
        na.omit %&gt;% ## Remove blank rows if there are fewer than 4
        paste(collapse=&quot;\n&quot;), ## Collapse multiple lines into one, separated by a line break
        by=name]</code></pre>
<p>Let’s check to make sure it worked.</p>
<pre class="r"><code>## Check it
talksCheck &lt;- talks[, .(name, nameWrap, nameLength=nchar(name))][order(-nameLength)]

## Compare the unwrapped and wrapped versions
unwrapped &lt;- talksCheck[1, cat(name)]</code></pre>
<pre><code>## The good, the bad and the ugly: What I learned while consulting across the business as a data scient</code></pre>
<pre class="r"><code>wrapped &lt;- talksCheck[1, cat(nameWrap)]</code></pre>
<pre><code>## The good, the bad
## and the ugly: What
## I learned while
## consulting across</code></pre>
</div>
<div id="find-overlapping-times" class="section level2" number="4.7">
<h2><span class="header-section-number">4.7</span> Find overlapping times</h2>
<p>Since we’re dealing with data here 🤪, it could be interesting to check for cases where multiple sessions
are scheduled at the same time and location. Using the <code>data.table::foverlaps</code> function, we can easily and quickly join
the table of talks to itself on the room location and start/end times and look for overlaps. First we set the key
columns that will be used in the join, making sure that the start and end times are the last two keys specified (as
required by <code>foverlaps</code>). Then we subset the results to remove cases where the session names being compared are
identical, since we don’t want to compare a talk to itself. In other words, we already know that Talk A is happening at
the same time and place as Talk A.</p>
<pre class="r"><code>## Select relevant columns
allTalks &lt;- talks[, .(locationName, startTime, endTime, name, speakerInfo)]

## Set the keys for the table
setkey(allTalks, locationName, startTime, endTime)

## Find the overlapping times
overlaps &lt;- foverlaps(allTalks, allTalks, type=&quot;within&quot;)[name!=i.name][order(locationName, startTime, name)]

## Clean up the names
#setnames(overlaps, gsub(&quot;i\\.&quot;, &quot;overlapping\\.&quot;, names(overlaps)))
overlaps[, mget(names(overlaps)[!names(overlaps) %like% &quot;i\\.&quot;])]</code></pre>
<pre><code>##    locationName           startTime             endTime
## 1:       Room 2 2020-01-30 11:16:00 2020-01-30 11:38:00
## 2:       Room 2 2020-01-30 11:16:00 2020-01-30 11:38:00
##                                  name
## 1: Designing Effective Visualizations
## 2:      How Rmarkdown changed my life
##                                                 speakerInfo
## 1:             Miriah Meyer (University of Utah, Professor)
## 2: Rob Hyndman (Monash University, Professor of Statistics)</code></pre>
<p>Uh oh. It might get a little awkward when the Effective Visualization crowd shows up to the RMarkdown party in Room 2
on Thursday at 11:16.</p>
<div style="margin:auto; width:480px;">
<a href="https://media.giphy.com/media/g7QIkzEDTEWKA/giphy.gif">
<img style="width:100%;" src="looknormal.gif" alt="Here they are, so look normal" />
<figcaption>
<img style="width:120px; float:right; padding-top:5px;" src="giphy.png" alt="Giphy logo" />
</figcaption>
<p></a></p>
</div>
<p><br></p>
</div>
</div>
<div id="visualize" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Visualize</h1>
<div id="take-1" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Take 1</h2>
<p>Now we’re finally ready to do something useful-ish! 🤨 Let’s use the <code>geom_rect</code> function from the
<a href="https://ggplot2.tidyverse.org/"><code>ggplot2</code> package</a> to plot each talk session as a rectangle. On the x-axis the box
will stretch from the start time to the end time. Room locations will be represented by different y-axis positions.
The name of the talk will be labeled with <code>geom_text</code>. Flip the switch and let’s see what we’ve got!</p>
<div style="margin:auto; width:480px;">
<a href="https://media1.giphy.com/media/3o6wrr3Vk5g3NnuASY/giphy.gif">
<img style="width:100%;" src="drumroll.gif" alt="Drum roll..." />
<figcaption>
<img style="width:120px; float:right; padding-top:5px;" src="giphy.png" alt="Giphy logo" />
</figcaption>
<p></a></p>
</div>
<p><br></p>
<pre class="r"><code>p1 &lt;-
  ggplot(talks, aes(
  ymin=as.ITime(startTime), ymax=as.ITime(endTime),
  xmin=as.numeric(factor(locationName))-0.45, xmax=as.numeric(factor(locationName))+0.45)) +
  geom_rect(fill=&quot;white&quot;, color=&quot;black&quot;) +
  geom_text(aes(
    y=as.ITime(startTime + (endTime-startTime)/2), x=as.numeric(factor(locationName)),
    label=substr(name, 0, 30)), angle=0) +
  scale_y_continuous(trans=&quot;reverse&quot;) +
  facet_wrap(~as.IDate(startTime), ncol=1)

p1</code></pre>
<p><img src="/./post/2020-01-20-schedule-for-rstudio-conf-2020l-talks/index.en_files/figure-html/unnamed-chunk-25-1.png" width="100%" /></p>
<div style="margin:auto; width:480px;">
<a href="https://media.giphy.com/media/67SXeoc8RLwvqCwn2F/giphy.gif">
<img style="width:100%;" src="idontlikeit.gif" alt="Uh-uh, I don't like it" />
<figcaption>
<img style="width:120px; float:right; padding-top:5px;" src="giphy.png" alt="Giphy logo" />
</figcaption>
<p></a></p>
</div>
<p><br></p>
<p>Ok, so it might need some “finessing”. I promise it looked better full screen on a 4K monitor 🤞. But
only a little.</p>
</div>
<div id="take-2" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Take 2</h2>
<p>Let’s see if we can do better…</p>
<div style="margin:auto; width:480px;">
<a href="https://media.giphy.com/media/MF3fDJIFZ0ORO/giphy.gif">
<img style="width:100%;" src="backontrack.gif" alt="How do we get back on the right track?" />
<figcaption>
<img style="width:120px; float:right; padding-top:5px;" src="giphy.png" alt="Giphy logo" />
</figcaption>
<p></a></p>
</div>
<p><br></p>
<p><code>ggplot2</code> has amazing superpowers for most data visualization tasks, and we could try to tweak our first take to make it
more readable. But it’s probably better in this case to switch to another tool that is more interactive and
“web native”. I investigated using <a href="https://github.com/davidgohel/ggiraph"><code>ggiraph</code></a> and
<a href="https://plot.ly/r/"><code>Plotly</code></a>; while they are both nice packages and good at what they do, they weren’t quite suited
for this task.</p>
<p>After more searching, I came across the <a href="https://github.com/daattali/timevis"><code>timevis</code> package</a>. According to the
package creator Dean Attali (<a href="https://twitter.com/daattali"><code>@daattali</code></a>), it is “based on the
<a href="http://visjs.org">vis.js</a> Timeline module and the <a href="http://www.htmlwidgets.org"><code>htmlwidgets</code></a> R package.” (Dean also
created <a href="https://github.com/daattali/beautiful-jekyll">beautiful-jekyll</a>, the basis for
<a href="https://themes.gohugo.io/beautifulhugo/">the Hugo template</a> I’m using for this blog. Thanks Dean!) Let’s give it a
try!</p>
<p>We’ll still use the <code>talks</code> table, but <code>timevis</code> requires a second table with grouping information. In our case, the
groups are the room locations. So before plotting anything, let’s get the room info in a separate table.</p>
<pre class="r"><code>rooms &lt;-
  talks[, .(id=locationName, content=locationName, order=as.numeric(factor(locationName)))][
    order(order)] %&gt;%
  unique
#rooms[, style:=sprintf(
#  &quot;color: %s; background-color: %s;&quot;,
#  ggsci::pal_simpsons(&quot;springfield&quot;)(nrow(rooms)),
#  ggsci::pal_simpsons(&quot;springfield&quot;, alpha=0.3)(nrow(rooms)))]</code></pre>
<p>Finally, we’re ready to create the visualization for the talk schedule. I won’t explain every bit of the code to create
the output, since the <code>timevis</code> <a href="https://github.com/daattali/timevis">documentation and examples</a> are pretty good. I
did spend a fair amount of time poring over the vis.js docs, especially the
<a href="https://visjs.github.io/vis-timeline/docs/timeline/#Configuration_Options">configuration options</a> and
<a href="https://visjs.github.io/vis-timeline/examples/timeline/">examples</a>, trying to determine
how to translate the Javascript instructions into R.</p>
<pre class="r"><code>hoverTemplate &lt;-
&quot;Category: %s
Title: %s
Time: %s to %s
Speaker(s): %s

%s&quot;

tv &lt;-
  timevis(
  talks[, .(
    id,
    start=startTime,
    end=endTime,
    title=sprintf(hoverTemplate,
                  categoryName, ## Category
                  name, ## Title
                  format(startTime, &quot;%I:%M%p&quot;), format(endTime, &quot;%I:%M%p&quot;), ## Time
                  speakerInfo, ## Speaker
                  gsub(&quot;&lt;.*?&gt;&quot;, &quot;&quot;, (description)) ## Description
    ),
    content=gsub(&quot;\\n&quot;, &quot;&lt;br&gt;&quot;, nameWrap),
    group=locationName,
    type=&quot;range&quot;,
    style)],
  groups=rooms,
  options=list(
    stack=FALSE, stackSubgroups=FALSE, horizontalScroll=TRUE, zoomKey=&quot;ctrlKey&quot;, width=&quot;100%&quot;,
    format=list(minorLabels=list(minute=&quot;LT&quot;, hour=&quot;LT&quot;)),
    end=&quot;2020-01-29 11:00:00&quot;, hiddenDates=list(start=&quot;2020-01-29 18:00:00&quot;, end=&quot;2020-01-30 08:00:00&quot;)
  )
)</code></pre>
</div>
</div>
<div id="final-result" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Final result</h1>
<hr>
<div id="htmlwidget-1" class="timevis html-widget" style="width:100%;height:480px;">
<div class="btn-group zoom-menu">
<button type="button" class="btn btn-default btn-lg zoom-in" title="Zoom in">+</button>
<button type="button" class="btn btn-default btn-lg zoom-out" title="Zoom out">-</button>
</div>
</div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"items":[{"id":"430f24c8-2860-4158-840c-49198318dfa2","start":"2020-01-29 09:00:00","end":"2020-01-29 09:05:00","title":"Category: \nTitle: Welcome to rstudio::conf 2020\nTime: 09:00AM to 09:05AM\nSpeaker(s): Hadley Wickham (RStudio, Chief Scientist)\n\n","content":"Welcome to<br>rstudio::conf 2020","group":"Room 2","type":"range","style":"color: white; background-color: #FED439b3; border-color: #FED439;"},{"id":"362fca53-0b9d-462c-b702-ea85c9ea10b2","start":"2020-01-29 09:05:00","end":"2020-01-29 10:00:00","title":"Category: Keynote\nTitle: Open Source Software for Data Science\nTime: 09:05AM to 10:00AM\nSpeaker(s): J.J. Allaire (Founder and CEO RStudio)\n\nOpen-source software is fundamentally necessary to ensure that the tools of data science are broadly accessible, and to provide a reliable and trustworthy foundation for reproducible research. This talk will delve into why open source software is so important and discuss the role of corporations as stewards of open source software. I'll also talk about how RStudio is structured and organized to pursue its mission of creating open source software for data science.\r\n","content":"Open Source<br>Software for Data<br>Science","group":"Room 2","type":"range","style":"color: white; background-color: #0B4947b3; border-color: #0B4947;"},{"id":"d8d901d9-bdb6-4392-83a9-3ad5addbbf53","start":"2020-01-29 10:00:00","end":"2020-01-29 11:00:00","title":"Category: Keynote\nTitle: Data, visualization, and designing with AI\nTime: 10:00AM to 11:00AM\nSpeaker(s): Fernanda Viegas (Google); Martin Wattenberg (Google)\n\nRecent progress in machine learning has raised a series of urgent questions: How can we train and debug deep learning models? How can we understand what is going on inside a neural network? And, perhaps most important, how can we design systems that serve people best? We'll show a series of examples from the People+AI Research (PAIR) initiative at Google--ranging from data visualizations for researchers, to tools for medical practitioners, to guidelines for designers--that illustrate how thinking carefully about data can lead to better tools, more effective design, and help humans and AI work together.\r\n","content":"Data,<br>visualization, and<br>designing with AI","group":"Room 2","type":"range","style":"color: white; background-color: #0B4947b3; border-color: #0B4947;"},{"id":"81b467b6-5239-4f3a-b67a-d8f58d33efbc","start":"2020-01-29 11:30:00","end":"2020-01-29 11:52:00","title":"Category: Case Study\nTitle: Professional Case Studies\nTime: 11:30AM to 11:52AM\nSpeaker(s): Katie Masiello (RStudio, Customer Success Representative)\n\nThe path to becoming a world-class, data-driven organization is daunting. The challenges you will likely face along the way can be thorny, and in some cases, seem outright impossible to overcome. How do you get teams that traditionally butt heads, such as IT and data science, to complement each other and work in unison? How can you efficiently scale the scope and reach of your data products as requirements change? Your time should be spent doing truly valuable work instead of updating charts and reports. How do you prevent the support structure behind your platform from toppling like a house of cards? Despite these challenges, we think that the end result is worth it: an organization that is equipped to make important decisions, with confidence, using data analysis that comes from a sustainable environment. We see this outcome every day.\r\n","content":"Professional Case<br>Studies","group":"Room 3","type":"range","style":"color: white; background-color: #2A87BDb3; border-color: #2A87BD;"},{"id":"1a28b485-9971-4c62-ac32-6603f7a6ce35","start":"2020-01-29 11:30:00","end":"2020-01-29 11:52:00","title":"Category: Education\nTitle: Meet You Where You R\nTime: 11:30AM to 11:52AM\nSpeaker(s): Lauren Chadwick (RStudio, Customer Success Representative)\n\nAt RStudio, we wake up and go to bed thinking about the positive impact that open source work and data science has had and can have on the world. To maximize this impact, we find three areas of investment absolutely critical to ensure our open source community keeps up with the world’s changes and outlives us all: 1. Find ways to make R more approachable. 2. Enable teams of all types &amp; sizes (educational, professional, etc.) to be able to leverage the work they’re doing in R, and effortlessly communicate that work to others. 3. Extend the language so our open-source community can continue to be at the forefront of innovation, no matter their preference of tool or language. Underpinning these investments is also the core belief that every data scientist, regardless of skill level, use-case, or professional experience, is an asset to our community. Whether you’re a student currently learning R, a Python fan looking to become multilingual, or the Head of Data Science at NASA, we want you to become a part of our journey. In return, we’ll do our best to ensure that journey is a fulfilling endeavor. This presentation will take a deeper dive into the ways in which you can utilize RStudio's educational offerings and enterprise toolchain in personal, educational, and corporate settings. educational offerings and enterprise toolchain in personal, educational, and corporate settings.\r\n","content":"Meet You Where You<br>R","group":"Room 2","type":"range","style":"color: white; background-color: #746C31b3; border-color: #746C31;"},{"id":"4f68c74e-57cc-4ce4-b940-0730ce426b4d","start":"2020-01-29 11:30:00","end":"2020-01-29 11:52:00","title":"Category: Production\nTitle: Deploying End-To-End Data Science with Shiny, Plumber, and Pins\nTime: 11:30AM to 11:52AM\nSpeaker(s): Alex Gold (RStudio, Solutions Engineer)\n\nIt’s easier than ever to craft a complete R-centric data science pipeline thanks to packages like Shiny, Plumber, and Pins. In this talk, you’ll learn how to use R to bring your modeling and visualization work into production. You’ll walk away with recipes, tips, and tricks to deploy data, models, and apps to ensure your work is as impactful as possible.\r\n","content":"Deploying<br>End-To-End Data<br>Science with Shiny,<br>Plumber, and Pins","group":"Room 1","type":"range","style":"color: white; background-color: #BEA687b3; border-color: #BEA687;"},{"id":"0b879607-6d0d-4e66-8811-e8b853f79624","start":"2020-01-29 11:30:00","end":"2020-01-29 11:52:00","title":"Category: Programming\nTitle: Simplified Data Quality Monitoring of Dynamic Longitudinal Data: A Functional Programming Approach\nTime: 11:30AM to 11:52AM\nSpeaker(s): Jacqueline Gutman (Flatiron Health)\n\nEnsuring the quality of data we deliver to customers or provide as inputs to models is often one of the most under-appreciated and yet time-consuming responsibilities of a modern data scientist. This task is challenging enough when working with static data, but when we have access to dynamic, longitudinal, continuously updating data, that complexity can become an asset. We will demonstrate how to to simplify data quality monitoring of dynamic data with a functional programming approach that enables early and actionable detection of data quality concerns. \r\n\r\nUsing purrr as well as tidyr and nested tibbles, we will illustrate the five key pillars of enjoyable, user-friendly data quality monitoring with relevant R code: Readability, Reproducibility, Efficiency, Robustness, and Compositionality. \r\n\r\nReadability: FP empowers us to abstract away from the mechanics and implementation of comparing two or more related datasets and move towards declaring the intent of features and metrics we want to compare. \r\n\r\nReproducibility: By avoiding side-effects and dependencies on external states and inputs, and using functional units which can be easily tested over a variety of inputs, FP reduces the burden to create reproducible code. Perhaps more importantly, FP supports not just reproducibility of results, but reproducibility of workflows that can be continually applied to dynamic datasets.\r\n\r\nEfficiency: FP enables more efficient code through lazy evaluation, caching, and simplifying implementation over parallel backends.\r\n\r\nRobustness: FP allows greater testability of our code through modularization and elegant error-handling, with customized fail-safes for data that differs in expected ways over time. \r\n\r\nCompositionality: FP encourages higher-level reasoning with functions, which in turn drives both readability--through higher-level, more abstract code--and robustness, through modifying function behavior in case errors are encountered.","content":"Simplified Data<br>Quality Monitoring<br>of Dynamic<br>Longitudinal Data:","group":"Room 4","type":"range","style":"color: white; background-color: #D4E3A2b3; border-color: #D4E3A2;"},{"id":"ed336435-51ae-4af8-adc0-4e755d531fca","start":"2020-01-29 11:53:00","end":"2020-01-29 12:15:00","title":"Category: Case Study\nTitle: How Vibrant Emotional Health Connected Siloed Data Sources and Streamlined Reporting Using R\nTime: 11:53AM to 12:15PM\nSpeaker(s): Sean Murphy (Vibrant, Senior Data Scientist)\n\nVibrant Emotional Health is the mental health not-for-profit behind the US National Suicide Prevention Lifeline, New York City's NYC Well program, and various other emotional health contact center programs and direct services. We engage in emotionally charged conversations with people experiencing a wide variety of mental health and emotional concerns, our programs vary in scope, in resources, and span several technologies. In addition, our data collection and reporting requirements change dynamically in response to emerging clinical needs and reporting requirements from our sponsors. In short, the data we collect is complex, often unstructured, and stored in a variety of sources. In this context, R Markdown Documents have allowed us to interface directly with multiple databases, Google Sheets, API's, csv's, and JSON stores to generate integrated reports. Organizing these reports into R packages with accompanying functions that standardize the calculation of KPI's and apply consistent themes across analyses has allowed us to improve the clarity and aesthetics of our reporting while reducing manual work that was previously needed to produce these reports. Building on this framework we have developed functions to standardize data connections, create reusable data visualizations, and generate reproducible analyses in response to ad hoc analytic requests. These same functions also facilitate the creation of Shiny dashboards where core visualizations that were previously only available in static reports can be manipulated directly by end users to explore clinical and operational trends. These dashboards also facilitate self service reporting by end users. We present here the framework we have developed for our organization wide and program specific packages, the types of functions and artifacts they include and our plans for future development.\r\n","content":"How Vibrant<br>Emotional Health<br>Connected Siloed<br>Data Sources and","group":"Room 3","type":"range","style":"color: white; background-color: #2A87BDb3; border-color: #2A87BD;"},{"id":"dd568377-e7e0-4baf-b63e-470e13508466","start":"2020-01-29 11:53:00","end":"2020-01-29 12:15:00","title":"Category: Education\nTitle: Data Science Education in 2022\nTime: 11:53AM to 12:15PM\nSpeaker(s): Greg Wilson (RStudio, Data Scientist & Professional Educator); Carl Howe (RStudio, Director of Education)\n\nMore people are learning data science every day, and there are more ways for them to learn than ever before. To understand where we are and where we might be going, this talk looks at what data science education could look like two years from now: far enough away that we can dream, but close enough that we can only dream a little. We explore the balance between automated and collaborative learning, different ways to deliver different kinds of lessons to different kinds of people, and ways in which our tools and practices could improve.\r\n","content":"Data Science<br>Education in 2022","group":"Room 2","type":"range","style":"color: white; background-color: #746C31b3; border-color: #746C31;"},{"id":"a572c454-fd91-4ed3-8609-abd06af157c4","start":"2020-01-29 11:53:00","end":"2020-01-29 12:15:00","title":"Category: Production\nTitle: We’re hitting R a million times a day so we made a talk about it\nTime: 11:53AM to 12:15PM\nSpeaker(s): Heather Nolis (T-Mobile, Machine Learning Engineer); Jacqueline Nolis (Nolis, LLC, Principal Data Scientist)\n\nOften reserved for Elite Engineers, production can be a perilous place for R users - but never fear! For the past year, we at T-Mobile have been sludging through production outages, nation-wide product launches, and all of the muck that floods from R models being hit over a million times every day. From “we’re strictly a java shop” to a devops team that proudly states “we support Java, node, and R,” this talk will cover the technical hiccups, interdisciplinary communication struggles, and an open-source R package {loadtest} that’s changed the way our team views performance testing. You too can dazzle your enterprise with the power of R.\r\n","content":"We’re hitting R a<br>million times a day<br>so we made a talk<br>about it","group":"Room 1","type":"range","style":"color: white; background-color: #BEA687b3; border-color: #BEA687;"},{"id":"90ef231d-c201-41cb-a91e-8918c05b22d7","start":"2020-01-29 11:53:00","end":"2020-01-29 12:15:00","title":"Category: Programming\nTitle: vctrs: Creating custom vector classes with the vctrs package\nTime: 11:53AM to 12:15PM\nSpeaker(s): Jesse Sadler (Loyola Marymount University, Lecturer)\n\nThe base R types of vectors enable the representation of an amazingly wide array of data types. There is so much you can do with R. However, there may be times when your data does not fit into one of the base types and/or you want to add metadata to vectors. vctrs is a developer-focused package that provides a clear path for creating your own S3-vector class, while ensuring that the classes you build integrate into user expectations for how vectors work in R. This presentation will discuss the why and how of using vctrs through the example of debkeepr, a package for integrating historical non-decimal currencies such as pounds, shillings, and pence into R. The presentation will provide a step-by-step process for developing various types of vectors and thinking through the design process of how vectors of different classes should work together.\r\n","content":"vctrs: Creating<br>custom vector<br>classes with the<br>vctrs package","group":"Room 4","type":"range","style":"color: white; background-color: #D4E3A2b3; border-color: #D4E3A2;"},{"id":"9071622c-13bc-4f15-964a-8d3b537a248e","start":"2020-01-29 12:16:00","end":"2020-01-29 12:38:00","title":"Category: Case Study\nTitle: Building a new data science pipeline for the FT with RStudio Connect\nTime: 12:16PM to 12:38PM\nSpeaker(s): George Kastrinakis (Financial Times, Senior Data Scientist)\n\nWe have recently implemented a new Data Science workflow and pipeline, using RStudio Connect and Google Cloud Services. This has vastly decreased our pipeline complexity, allowing us to bring our models and products into scheduled production more quickly. In addition, our workflow, working closely together as a team on all projects on a regular two-week sprint cycle, has increased the range of projects we have been able to take on and complete. To detail some of the key lessons we’ve learned (and some of the difficulties!), we’ll walk you through one of our recent sprints, where we productionalised the generation of a suite of behavioural and demographic features so that they can be more easily plugged in to a range of models and used across the business by the FT’s platform and product teams.\r\n","content":"Building a new data<br>science pipeline<br>for the FT with<br>RStudio Connect","group":"Room 3","type":"range","style":"color: white; background-color: #2A87BDb3; border-color: #2A87BD;"},{"id":"b6430542-cb37-4d31-8371-42ad803918ca","start":"2020-01-29 12:16:00","end":"2020-01-29 12:38:00","title":"Category: Education\nTitle: Data science education as an economic and public health intervention in East Baltimore\nTime: 12:16PM to 12:38PM\nSpeaker(s): Jeff Leek (Johns Hopkins Bloomberg School of Health, Professor of Biostatistics, Problem Forward Data Science- Chief Data Scientist)\n\n","content":"Data science<br>education as an<br>economic and public<br>health intervention","group":"Room 2","type":"range","style":"color: white; background-color: #746C31b3; border-color: #746C31;"},{"id":"ad815977-9392-4542-8274-f006cf237fcc","start":"2020-01-29 12:16:00","end":"2020-01-29 12:38:00","title":"Category: Production\nTitle: Growth Hacking with R - Product Analytics at Scale using R and RStudio\nTime: 12:16PM to 12:38PM\nSpeaker(s): Andrew Mangano (Salesforce, Data Intelligence Lead)\n\nSalesforce is not only a cloud software solution out of the box, but also a highly customizable platform that can be modified for a wide range of use cases. In addition to complexity, customer trust is our #1 company value and customer data privacy is abstracted from everyone outside of the customer. Product and Growth Analytics is an emerging field separate from business analytics and data science and focuses on building software product that improve user retention and engagement. Companies like Facebook and AirBnB have robust data science teams focused on product analytics. At Salesforce however, given the scale, customization, and privacy values, product data science is not so straightforward. Utilizing R and Rstudio tools for collaboration and reproducible analytics, the Data Intelligence team is able to solve complex problems at enterprise scale. This talk will preview anonymized predictive and growth analytics work while also highlighting how we work and collaborate cross platform and languages (Python via reticulate).\r\n","content":"Growth Hacking with<br>R - Product<br>Analytics at Scale<br>using R and RStudio","group":"Room 1","type":"range","style":"color: white; background-color: #BEA687b3; border-color: #BEA687;"},{"id":"5fec742c-53f3-45b6-8c87-ff4bad5e5257","start":"2020-01-29 12:16:00","end":"2020-01-29 12:38:00","title":"Category: Programming\nTitle: Asynchronous programming in R\nTime: 12:16PM to 12:38PM\nSpeaker(s): Winston Chang (RStudio, Software Engineer)\n\nWriting regular R code is straightforward: you tell R to do something, it does it, and then it returns control back to you. This is called synchronous programming. However, if you use R to coordinate threads, processes, or network communication, the regular model may be unable to do what you want, or it may only be able to do it with a significant performance penalty. In this talk I'll explain how asynchronous programming with the later package can handle these kinds of programming problems. I'll also show how to provide a synchronous interface for asynchronous code, so that users will have a simple, familiar way to use your code.\r\n","content":"Asynchronous<br>programming in R","group":"Room 4","type":"range","style":"color: white; background-color: #D4E3A2b3; border-color: #D4E3A2;"},{"id":"577654d1-fcb3-4f67-9be3-bc46ab816ce3","start":"2020-01-29 12:39:00","end":"2020-01-29 12:59:00","title":"Category: Case Study\nTitle: How to win an AI Hackathon, without using AI\nTime: 12:39PM to 12:59PM\nSpeaker(s): Colin Gillespie (Jumping Rivers)\n\nAnyone reading a newspaper or listening to the news is led to believe that AI is the solution to all problems. From self-driving cars to detecting disease to catching fraud, there doesn’t seem to be a situation that AI can’t tackle. Once “big data” is thrown into the mix, the AI solution is all but certain. But is AI always needed? Over the last eighteen months, Jumping Rivers has entered (and won) four Hackathons. All Hackathons were characterised with “big data” and the need to improve prediction. All Hackathons were won without using AI (or any sort of machine learning). This talk will focus on one particular competition around reducing leakage at Northumbrian Water. Using a combination of R, Shiny, and tidyverse (and a few other tricks), we were able to demonstrate within the short Hackathon time frame that clear presentation of data to the front line engineers was more likely to reduce leakage, than simply providing vague estimates of a potential future leak\r\n","content":"How to win an AI<br>Hackathon, without<br>using AI","group":"Room 3","type":"range","style":"color: white; background-color: #2A87BDb3; border-color: #2A87BD;"},{"id":"800fbfd5-d1b9-4ab0-a795-108ce2d51d1d","start":"2020-01-29 12:39:00","end":"2020-01-29 12:59:00","title":"Category: Education\nTitle: Of Teacups, Giraffes, & R Markdown\nTime: 12:39PM to 12:59PM\nSpeaker(s): Desiree De Leon (Emory University, PhD Student)\n\nHow do you make your R Markdown lessons feel friendly for learners you’ll never meet? How do you make it engaging so they sit and stay a while? How do you make it memorable so they come back to visit again? In this talk, I’ll share lessons learned from my experience of making a series of online statistics modules (co-authored by Hasse Walum) that feel accessible and fun-- housed entirely in an R Markdown site, complete with a whimsical, illustrated narrative about teacup giraffes. I’ll show how adding good characters with your audience in mind, good design, and good play helped me make the most of HTML output. To help you get started, I’ll share resources that Alison Hill and I have developed--including a series of cookbooks and out-of-the-box templates-- so that you will have a leg up on applying these ideas to R Markdown collections of your own.\r\n","content":"Of Teacups,<br>Giraffes, & R<br>Markdown","group":"Room 2","type":"range","style":"color: white; background-color: #746C31b3; border-color: #746C31;"},{"id":"cbe85c76-9313-43d7-bcd3-ba4f7816526f","start":"2020-01-29 12:39:00","end":"2020-01-29 12:59:00","title":"Category: Production\nTitle: Practical Plumber Patterns\nTime: 12:39PM to 12:59PM\nSpeaker(s): James Blair (RStudio, Solutions Engineer)\n\nPlumber is a package that allows R users to create APIs out of R functions. This flexible approach allows R processes to be accessed by toolchains and frameworks outside of R. In this talk, we'll look at useful patterns for developing and working with robust APIs built in R using Plumber.","content":"Practical Plumber<br>Patterns","group":"Room 1","type":"range","style":"color: white; background-color: #BEA687b3; border-color: #BEA687;"},{"id":"f6bc2b7a-ea99-4778-a513-9659f50c9d68","start":"2020-01-29 12:39:00","end":"2020-01-29 12:59:00","title":"Category: Programming\nTitle: Azure Pipelines and GitHub Actions\nTime: 12:39PM to 12:59PM\nSpeaker(s): Jim Hester (RStudio, Software Engineer)\n\nOpen source R packages on GitHub often take advantage of continuous integration services to automatically check their packages for errors. This is very useful to catch things quickly, as well and increasing confidence for proposed changes, as the Pull Requests can be checked before they are merged. Travis-CI and Appveyor are the most popular current methods. However newer services, Azure Pipelines and GitHub Actions, show promise for being more powerful and simpler to configure and debug. I will discuss these services and demonstrate some of their capabilities and how to configure them for your own use in packages and reports.","content":"Azure Pipelines and<br>GitHub Actions","group":"Room 4","type":"range","style":"color: white; background-color: #D4E3A2b3; border-color: #D4E3A2;"},{"id":"03d95381-eafd-47d2-9fc5-1603b17254ae","start":"2020-01-29 14:15:00","end":"2020-01-29 14:37:00","title":"Category: Community\nTitle: If you build it, they will come...but then what? Facilitating communities of practice in R\nTime: 02:15PM to 02:37PM\nSpeaker(s): Kate Hertweck (Fred Hutchinson Cancer Research Center, Bioinformatics Training Manager)\n\nWhy did you learn R? Chances are good that if you're an attendee of rstudio::conf, you've found a community of R coders who are willing to share their knowledge and learn with you. While it's possible to develop expert R coding skills in isolation, most software development and data analysis projects benefit from groups of people working collaboratively, and R communities are unparalleled in their inclusivity and commitment to learning collectively. Such communities, whether they support R coders at a single institution, geographic region, or online, require deliberate planning and effort to develop and sustain. How do you create a group culture that encompasses R users of various skill levels who may be working on diverse problems? How do you assess what members of a community need or prefer? How do you encourage investment and cohesion so the group will sustain itself? This talk will describe potential pitfalls and impediments to creating and facilitating cooperative learning communities for R coding, and will allow you to identify potential strategies for overcoming these challenges so you can continue giving back to the R communities that supported you along the way.\r\n","content":"If you build it,<br>they will<br>come...but then<br>what? Facilitating","group":"Room 2","type":"range","style":"color: white; background-color: #360335b3; border-color: #360335;"},{"id":"e056bbd6-c45e-4d83-bfb8-6878748f9984","start":"2020-01-29 14:15:00","end":"2020-01-29 14:37:00","title":"Category: Finance\nTitle: 15 Years of R in Quantitative Finance\nTime: 02:15PM to 02:37PM\nSpeaker(s): Brandon Farr (Copper Rock Capital Partners, Sr Quant)\n\nUse of R in the investment industry is established and growing. This talk will discuss changes seen in 15 years of practice within asset management firms. I hope discussion of lessons learned and recommendations will benefit those currently in finance and those interested in hearing how the flexibility of R manifests in the financial world.\r\n","content":"15 Years of R in<br>Quantitative<br>Finance","group":"Room 4","type":"range","style":"color: white; background-color: #E7B178b3; border-color: #E7B178;"},{"id":"9ee77f71-184c-40e2-b7cf-c0974427749b","start":"2020-01-29 14:15:00","end":"2020-01-29 14:37:00","title":"Category: Interface\nTitle: Accelerating Analytics with Apache Arrow\nTime: 02:15PM to 02:37PM\nSpeaker(s): Neal Richardson (Ursa Labs / RStudio, Director of Engineering)\n\nThe Apache Arrow project is a cross-language development platform for in-memory data designed to improve system performance, memory use, and interoperability. This talk presents recent developments in the 'arrow' package, which provides an R interface to the Arrow C++ library. We'll cover the goals of the broader Arrow project, how to get started with the 'arrow' package in R, some general concepts for working with data efficiently in Arrow, and a brief overview of upcoming features.\r\n","content":"Accelerating<br>Analytics with<br>Apache Arrow","group":"Room 3","type":"range","style":"color: white; background-color: #4D3635b3; border-color: #4D3635;"},{"id":"4723a69d-7a95-4e44-94bf-964972e221cf","start":"2020-01-29 14:15:00","end":"2020-01-29 14:38:00","title":"Category: Shiny\nTitle: Production-grade Shiny Apps with golem\nTime: 02:15PM to 02:38PM\nSpeaker(s): Colin Fay (ThinkR, Data Scientist & R Hacker)\n\nShiny is an amazing tool when it comes to creating web applications with R. Almost anybody can get a small Shiny App in a matter of minutes, provided they have a basic knowledge of R. As of today, we can safely tell that it has become the de-facto tool for web application in the R world. Building a proof-of-concept application is easy, but things change when the application becomes larger and more complex, and especially when it comes to sending that app to production—until recently there hasn't been any real framework for building and deploying production-grade Shiny Apps. This is where 'golem' comes into play: offering Shiny developers an opinionated framework for creating production-ready Shiny Applications. With 'golem', Shiny developers now have a toolkit for making a stable, easy-to-maintain, and robust for production web application with R. 'golem' has been developed to abstract away the most common engineering tasks (for example, module creation, addition of external CSS or JavaScript file, ...), so you can focus on what matters: building the application. And once your application is ready to be deployed, 'golem' guides you through testing, and brings you tools for deploying to common platforms. In this talk, Colin and Vincent will present the 'golem' package, first talking about the \"why 'golem'?\", then presenting the general philosophy behind this framework, and help you get started building your first Shiny App with 'golem'.\r\n","content":"Production-grade<br>Shiny Apps with<br>golem","group":"Room 1","type":"range","style":"color: white; background-color: #FD8CC1b3; border-color: #FD8CC1;"},{"id":"facdb7b2-d84f-4db6-ba51-9bb39daef896","start":"2020-01-29 14:38:00","end":"2020-01-29 15:00:00","title":"Category: Community\nTitle: Embracing R in the Geospatial Community\nTime: 02:38PM to 03:00PM\nSpeaker(s): Tina Cormier (Indigo, Data Scientist, Remote Sensing)\n\nGeospatial analysts work in a wide range of positions within almost every industry. They work in government, non-profit, academic, and private institutions using geospatial data and technology to answer questions about the environment, agriculture, climate, urban planning and design, marketing, public health, transportation, and myriad other topics. A typical day may include data prep/cleaning, field work, cartography, image analysis, vector analysis, feature engineering, modeling, or database management. This diverse group necessarily uses a diverse set of tools. In this talk, we will explore how R fits into the spatial analyst’s toolkit. What does the geo community think of R? Who uses it? What groups avoid it? What geo-packages are used most? How can we, as a community, make R more appealing for geospatial scientists?\r\n","content":"Embracing R in the<br>Geospatial<br>Community","group":"Room 2","type":"range","style":"color: white; background-color: #360335b3; border-color: #360335;"},{"id":"3b1ed201-fae3-4986-b31b-3bc0b855a881","start":"2020-01-29 14:38:00","end":"2020-01-29 15:00:00","title":"Category: Finance\nTitle: Deep Learning Extraction for Counterparty Risk Signals from a Corpus of Millions of Documents\nTime: 02:38PM to 03:00PM\nSpeaker(s): Moody Hadi (S&P Global - Market Intelligence, Group Manager)\n\nChina has been experiencing rapid growth over the last decade due to economically friendly reforms and a growing skilled and young population. With this increasing growth, China’s interconnectedness with the global economy has increased significantly. In parallel to this economic evolution, technology has experienced rapid acceleration, which has enabled firms and governments to track and record vast amounts of data. The side effect of this unstructured big data growth is that datasets may be polluted, meaning information can be conflicting, missing, and/or unreliable. This creates a gap in the ability to provide transparency to the exposed firms importing from China: both timely early warning signals and wide coverage of small- and medium-sized enterprises (SMEs). We have been able to address this problem for our end-users by using deep learning to extract information value and opinion from a public corpus to create the needed transparency. Our data science &amp; machine learning stack uses connect, shiny, reticulate, tensorflow and scikit-learn to build the interactive solution to our clients and deploy it using spark and airflow.\r\n","content":"Deep Learning<br>Extraction for<br>Counterparty Risk<br>Signals from a","group":"Room 4","type":"range","style":"color: white; background-color: #E7B178b3; border-color: #E7B178;"},{"id":"7ae003b1-016e-4706-9dd0-60bec53ab0b4","start":"2020-01-29 14:38:00","end":"2020-01-29 15:00:00","title":"Category: Interface\nTitle: Updates on Spark, MLflow, and the broader ML ecosystem\nTime: 02:38PM to 03:00PM\nSpeaker(s): Javier Luraschi (RStudio, Software Engineer)\n\n","content":"Updates on Spark,<br>MLflow, and the<br>broader ML<br>ecosystem","group":"Room 3","type":"range","style":"color: white; background-color: #4D3635b3; border-color: #4D3635;"},{"id":"5ac2387d-4ea5-48ac-90a1-8b9333eb7592","start":"2020-01-29 14:38:00","end":"2020-01-29 15:00:00","title":"Category: Shiny\nTitle: Making the Shiny Contest\nTime: 02:38PM to 03:00PM\nSpeaker(s): Mine Çetinkaya-Rundel (RStudio, Educator)\n\nIn January 2019 RStudio launched the first-ever Shiny contest to recognize outstanding Shiny applications and to share them with the community. We received 136 submissions for the contest and reviewing them was incredibly inspiring and humbling. In this talk, we shine a spotlight on the backstage: the inspiration behind the contest, the process of evaluation, what we learned about Shiny developers and how we can better support them, and what we learned about running contests and how we hope to improve the Shiny Contest experience. We also highlight some of the winning apps as well as the newly revamped Shiny Gallery, which features many noteworthy contest submissions. Finally, we introduce the new process for submitting your apps to the Shiny Gallery and, of course, to Shiny Contest 2020!\r\n","content":"Making the Shiny<br>Contest","group":"Room 1","type":"range","style":"color: white; background-color: #FD8CC1b3; border-color: #FD8CC1;"},{"id":"0455609a-cf61-44d1-a95b-3b97080c32a4","start":"2020-01-29 15:01:00","end":"2020-01-29 15:23:00","title":"Category: Community\nTitle: The development of \"datos\" package for the R4DS Spanish translation\nTime: 03:01PM to 03:23PM\nSpeaker(s): Riva Quiroga (The Programming Historian, Editor)\n\n","content":"The development of<br>\"datos\" package for<br>the R4DS Spanish<br>translation","group":"Room 2","type":"range","style":"color: white; background-color: #360335b3; border-color: #360335;"},{"id":"cc1f0c0d-a107-45fe-b7cb-bdaa3fb7c9e2","start":"2020-01-29 15:01:00","end":"2020-01-29 15:23:00","title":"Category: Finance\nTitle: Rpanda trading simulation - from an idea to a multi-user shiny app\nTime: 03:01PM to 03:23PM\nSpeaker(s): Nima Safaian (rpanda, Partner)\n\nThe idea of rpanda commodities trading simulation was many years in the making. As energy trading professionals working in the industry, we had developed insights around how to make risk/reward market calls, and what skills make someone an exceptional commodities trader. Traders are one of the most expensive seats in terms of monetizing value from the assets. We developed rpanda as a simulated environment which replicates closely how real-life physical commodities trading works in order to assist talent development and selection, both in academics and enterprise. My co-founder and I did not know how to design production-ready software, but we always had used R/Shiny for market analysis in our corporate jobs. Rather than hiring expensive app developers, we decided to do it ourselves. We used Rstudio development stack such as Rstudio Connect and open source tools, like plumber to turn our idea into a production-ready app that is used by University of Alberta classes. In this presentation, we share our journey, technical challenges, and how we overcame them.\r\n","content":"Rpanda trading<br>simulation - from<br>an idea to a<br>multi-user shiny","group":"Room 4","type":"range","style":"color: white; background-color: #E7B178b3; border-color: #E7B178;"},{"id":"23235ff7-392d-430f-802c-4b4c849c8d0f","start":"2020-01-29 15:01:00","end":"2020-01-29 15:23:00","title":"Category: Interface\nTitle: What's new in TensorFlow for R\nTime: 03:01PM to 03:23PM\nSpeaker(s): Daniel Falbel (RStudio, Software Engineer)\n\nTensorFlow is the most popular open-source platform for machine learning and it's ecosystem is evolving incredibly fast. In this talk we will explore what's new in TensorFlow 2.0 as well as how to build data pre-processing pipelines using the tfdatasets package and how to use pre-trained models with tfhub.\r\n","content":"What's new in<br>TensorFlow for R","group":"Room 3","type":"range","style":"color: white; background-color: #4D3635b3; border-color: #4D3635;"},{"id":"b8e20e44-a193-494a-9ee7-4183d4bfa583","start":"2020-01-29 15:01:00","end":"2020-01-29 15:23:00","title":"Category: Shiny\nTitle: Styling Shiny apps with Sass and Bootstrap 4\nTime: 03:01PM to 03:23PM\nSpeaker(s): Joe Cheng (RStudio, CTO)\n\nCustomizing the style--fonts, colors, margins, spacing--of Shiny apps has always been possible, but never as easy as we’d like it to be. Canned themes like those in the shinythemes package can easily make apps look slightly less generic, but that’s small consolation if your goal is to match the visual style of your university, corporation, or client.\r\nIn theory, one can \"just\" use CSS to customize the appearance of your Shiny app, the same as any other web application. But in practice, the use of large CSS frameworks like Bootstrap means significant CSS expertise is required to comprehensively change the look of an app.\r\nRelief is on the way. As part of a round of upgrades to Shiny’s UI, we’ve made fundamental changes to the way R users can interact with CSS, using new R packages we’ve created around Sass and Bootstrap 4. In this talk, we’ll show some of the features of these packages and tell you how you can take advantage of them in your apps.\r\n","content":"Styling Shiny apps<br>with Sass and<br>Bootstrap 4","group":"Room 1","type":"range","style":"color: white; background-color: #FD8CC1b3; border-color: #FD8CC1;"},{"id":"4e0fd38c-2f91-43b8-8eb9-aba98a7b7e3d","start":"2020-01-29 15:24:00","end":"2020-01-29 15:44:00","title":"Category: Community\nTitle: R: Then and Now\nTime: 03:24PM to 03:44PM\nSpeaker(s): Jared Lander (Lander Analytics, Chief Data Scientist)\n\nR has changed a lot since the meetup was founded 10 years ago. Back then we were using base graphics (or lattice) and the apply family of functions and we didn't have pipes. At the time there was an impressive 1800 packages on CRAN, now there are over 15,000 extending R's reach far beyond its traditional domain of statistics and machine learning into publishing, website building and video generation. The community has grown and changed dramatically during that time, with the New York meetup alone going from 25 to over 10,000 members. During this talk we go through a then-and-now of R code and community to palpably see how everything has changed.\r\n","content":"R: Then and Now","group":"Room 2","type":"range","style":"color: white; background-color: #360335b3; border-color: #360335;"},{"id":"dde422a6-90a4-4afa-af7a-035a7f876737","start":"2020-01-29 15:24:00","end":"2020-01-29 15:44:00","title":"Category: Finance\nTitle: The good, the bad and the ugly: What I learned while consulting across the business as a data scient\nTime: 03:24PM to 03:44PM\nSpeaker(s): Ben Barnard (Wells Fargo, Data Scientist)\n\nA collection of data science stories about current problems that data scientists might face while working in academia, industry, and government. Some lessons learned, some situations avoided, what I learned, and how I survived my journey. First, I discuss the struggle of advocating for R when senior leaders decide Python is the only appropriate product. Then, I describe why donut charts are superior to pie charts, and why we should all be using them. Finally, the case of the uncatchable “drive-by” stakeholder and where to find them. The fight is real, and the path is long for the evangelical data scientist.\r\n","content":"The good, the bad<br>and the ugly: What<br>I learned while<br>consulting across","group":"Room 4","type":"range","style":"color: white; background-color: #E7B178b3; border-color: #E7B178;"},{"id":"2a03d211-bb38-4617-a4c9-48ff1e9ab273","start":"2020-01-29 15:24:00","end":"2020-01-29 15:44:00","title":"Category: Interface\nTitle: Deep Learning with R\nTime: 03:24PM to 03:44PM\nSpeaker(s): Paige Bailey (Google, Product Manager)\n\n","content":"Deep Learning with<br>R","group":"Room 3","type":"range","style":"color: white; background-color: #4D3635b3; border-color: #4D3635;"},{"id":"0bc552f1-b70a-439c-90cc-4f3c83b45b10","start":"2020-01-29 15:24:00","end":"2020-01-29 15:44:00","title":"Category: Shiny\nTitle: Reproducible Shiny apps with shinymeta\nTime: 03:24PM to 03:44PM\nSpeaker(s): Carson Sievert (RStudio, Software Engineer)\n\nShiny makes it easy to take domain logic from an existing R script and wrap some reactive logic around it to produce an interactive webpage where others can quickly explore different variables, parameter values, models/algorithms, etc. Although the interactivity is great for many reasons, once an interesting result is found, it’s more difficult to prove the correctness of the result since: (1) the result can only be (easily) reproduced via the Shiny app and (2) the relevant domain logic which produced the result is obscured by Shiny’s reactive logic. The R package shinymeta provides tools for capturing and exporting domain logic for execution outside of a Shiny runtime (so that others can reproduce Shiny-based result(s) from a new R session).","content":"Reproducible Shiny<br>apps with shinymeta","group":"Room 1","type":"range","style":"color: white; background-color: #FD8CC1b3; border-color: #FD8CC1;"},{"id":"914fa687-23c1-45ae-8a2f-fa5889cc9f20","start":"2020-01-29 16:00:00","end":"2020-01-29 16:23:00","title":"Category: Case Study\nTitle: Journalism with RStudio, R, and the tidyverse\nTime: 04:00PM to 04:23PM\nSpeaker(s): Larry Fenn (Associated Press, Journalist)\n\nThe Associated Press data team primarily uses R and the tidyverse as the main tool for doing data processing and analysis. In this talk, some of the technology behind the published stories will be showcased: - Using dbplyr to work off a hosted database containing 380 million opioid records to identify \"pill mills\". - Using open-sourced AP style templates for R Markdown and ggplot to quickly produce graphics and reports off breaking news. - Using R Markdown and htmlwidgets to give reporters and editors interactive reports to identify reporting leads.\r\n","content":"Journalism with<br>RStudio, R, and the<br>tidyverse","group":"Room 3","type":"range","style":"color: white; background-color: #2A87BDb3; border-color: #2A87BD;"},{"id":"b023451f-66c2-42c2-be21-18cd10ba3ef8","start":"2020-01-29 16:00:00","end":"2020-01-29 16:22:00","title":"Category: Learning and Using R\nTitle: Flipbooks\nTime: 04:00PM to 04:22PM\nSpeaker(s): Evangeline Reynolds (University of Denver, Dr.)\n\nGood examples facilitate accomplishing new or unpracticed tasks in a programmatic workflow. Tools for communicating examples have improved in recent years. Especially embraced are tools that show code and its resultant output immediately thereafter --- the case of `Jupytr` notebooks and `Rmarkdown` documents. But creators using these tools often must choose between big-picture or narrow-focus demonstration; creators tend to either demo a complete code pipeline that accomplishes a realistic task or instead demonstrate a minimal example which makes clear the behavior of a particular function, but how it might be used in a larger project isn't clear. Flipbooks help address this problem, allowing the creator to present a full demonstration which accomplishes a real task, and gives the viewer the opportunity to focus on unfamiliar steps. A set of flipbook building functions parse code in a data manipulation or visualization pipeline and then build it back up incrementally. Aligned superimposition of new code and output atop previous code and output makes it easy to identify how each code change triggers changes in output. The presentation will guide attendees in creating their own Flipbooks (with Xaringan slides) or mini Flipbooks (gif output).\r\n","content":"Flipbooks","group":"Room 1","type":"range","style":"color: white; background-color: #7C9FD1b3; border-color: #7C9FD1;"},{"id":"89a098cc-e64c-478d-815f-77acab171676","start":"2020-01-29 16:00:00","end":"2020-01-29 16:22:00","title":"Category: Pharma\nTitle: Approaches to Assay Processing Package Validation\nTime: 04:00PM to 04:22PM\nSpeaker(s): Ellis Hughes (Fred Hutch Cancer Research Center)\n\nIn this talk I will discuss the steps that have been created for validating internally generated R packages at SCHARP (Statistical Center for HIV/AIDS Research and Prevention) and the lessons learned while creating packages as a team. Housed within Fred Hutch, SCHARP is an instrumental partner in the research and clinical trials surrounding HIV prevention and vaccine development. Part of SCHARP’s work involves analyzing experimental biomarkers and endpoints which change as the experimental question, analysis methods, antigens measured, and assays evolve. Maintaining a validated code base that is rigid in its output format, but flexible enough to cater a variety of inputs with minimal custom coding has proven to be important for reproducibility and scalability. SCHARP has developed several key steps in the creation, validation, and documentation of R packages that take advantage of R’s packaging functionality. First, the programming team works with leadership to define specifications and lay out a roadmap of the package at the functional level. Next, statistical programmers work together to develop the package, taking advantage of the rich R ecosystem of packages for development such as roxygen2, devtools, usethis, and testthat. Once the code has been developed, the package is validated to ensure it passes all specifications using a combination of testthat and rmarkdown. Finally, the package is made available for use across the team on live data. These procedures set up a framework for validating assay processing packages that furthers the ability of Fred Hutch to provide world-class support for our clinical trials.\r\n","content":"Approaches to Assay<br>Processing Package<br>Validation","group":"Room 4","type":"range","style":"color: white; background-color: #9591ACb3; border-color: #9591AC;"},{"id":"8e583082-de3d-4ba0-90c7-5b0a42c0b28e","start":"2020-01-29 16:00:00","end":"2020-01-29 16:22:00","title":"Category: Programming\nTitle: Getting things logged\nTime: 04:00PM to 04:22PM\nSpeaker(s): Gergely Daroczi (System1, Senior Director of Data Operations)\n\nOne of the greatest strength of R is the ease and speed of developing a prototype (let it be a report or dashboard, a statistical model or rule-based automation to solve a business problem etc), but deploying to production is not a broadly discussed topic despite its importance. This hands-on talk focuses on best practices and actual R packages to help transforming the prototypes developed by business analysts and data scientist into production jobs running in a secured and monitored environment that is easy to maintain -- discussing the importance of logging, securing credentials, effective helper functions to connect to database, open-source and SaaS job schedulers, dockerizing the run environment and scaling infrastructure.\r\n","content":"Getting things<br>logged","group":"Room 2","type":"range","style":"color: white; background-color: #D4E3A2b3; border-color: #D4E3A2;"},{"id":"ccae356c-f8ba-4549-ad55-5a1993a446b0","start":"2020-01-29 16:23:00","end":"2020-01-29 16:45:00","title":"Category: Case Study\nTitle: Putting the Fun in Functional Data: A tidy pipeline to identify routes in NFL tracking data\nTime: 04:23PM to 04:45PM\nSpeaker(s): Dani Chu (NHL Seattle, Quantitative Analyst - Statistics)\n\nCurrently in football many hours are spent watching game film to manually label the routes run on passing plays. Using tracking data, each route can be described as a sequence of spatial-temporal measurements that varies in length depending on the duration of the play. This data can be conveniently analyzed using nested columns in tidyr and purrr. We demonstrate how model-based curve clustering using Bernstein polynomial basis functions (i.e. Bézier curves) fit using the Expectation Maximization algorithm can cluster route trajectories. Each cluster can then be labelled to obtain route names for each route and create route trees for all receivers. The clusters and routes can be visualized nicely using ggplot and seen developing over time using gganimate.\r\n","content":"Putting the Fun in<br>Functional Data: A<br>tidy pipeline to<br>identify routes in","group":"Room 3","type":"range","style":"color: white; background-color: #2A87BDb3; border-color: #2A87BD;"},{"id":"511bebe5-9ccc-4e61-adbb-fd70df5a3e0d","start":"2020-01-29 16:23:00","end":"2020-01-29 16:45:00","title":"Category: Learning and Using R\nTitle: Learning R with humorous side projects\nTime: 04:23PM to 04:45PM\nSpeaker(s): Ryan Timpe (The LEGO Group, Senior Data Scientist)\n\nWhat should you name a new dinosaur discovery, according to neural networks? Which season of The Golden Girls should you watch when playing a drinking game? How can you build a LEGO set for the lowest price? R is constantly evolving, so as users, we’re constantly learning. Over the past few years, I’ve found that working on side projects is great for hands-on learning - and for me, the more absurd the project, the better. Side projects provide a safe, low-stakes environment to learn new packages and methodologies before using them in work or in production. Sharing those projects can help publicize the package and increase its accessibility, benefiting both the original author and future users. In this talk, I’ll share my experiences with side projects for learning state-of-the-art data science tools and growing as an R user, including how one project helped me land my dream job.\r\n","content":"Learning R with<br>humorous side<br>projects","group":"Room 1","type":"range","style":"color: white; background-color: #7C9FD1b3; border-color: #7C9FD1;"},{"id":"5c780b5f-34ed-44c3-9c96-9e64637f8703","start":"2020-01-29 16:23:00","end":"2020-01-29 16:45:00","title":"Category: Pharma\nTitle: Building a native iPad dashboard using plumber and RStudio Connect in Pharma\nTime: 04:23PM to 04:45PM\nSpeaker(s): Aymen Waqar (Astellas Pharma US, Data Science Manager)\n\nAs companies are becoming aware of the need to embrace data-driven solutions, R has gained a huge momentum over recent years. Getting the insights to users has become a very important factor of Data Scientist work. While our world has advanced there is a need to build not only web applications, but also applications on mobile that are available offline. We would like to share with you how within months we have gone from nothing to a production-ready application that handles 500 concurrent users in healthcare. There are plenty of challenges to solve including restricted environments, internal processes and users availability. We will show you how to overcome them and iterate fast, navigating through complex infrastructure and integrating with proxy architecture to serve applications to end users in compliant manner. With RStudio Connect and Plumber you can deploy a scalable REST API that can feed insights to your users. This allows you to go one step further and implement native applications for tablets and smartphones. With the right tools, mindset and priorities you can achieve personal success by introducing a digital transformation within your organization, starting with something as small as converting a business critical Excel file that is slow, difficult to edit and maintain, to a robust application. Step by step your organization will evolve and become empowered by your insights uncovering even more untapped potential.\r\n","content":"Building a native<br>iPad dashboard<br>using plumber and<br>RStudio Connect in","group":"Room 4","type":"range","style":"color: white; background-color: #9591ACb3; border-color: #9591AC;"},{"id":"09d8197b-cb6a-4b38-a345-3bb8231d3d9f","start":"2020-01-29 16:23:00","end":"2020-01-29 16:45:00","title":"Category: Programming\nTitle: Technical debt is a social problem\nTime: 04:23PM to 04:45PM\nSpeaker(s): Gordon Shotwell (Socure, Senior Data Scientist)\n\nTechnical debt is a big problem for the R community. Even though R has excellent support for testing, documentation and packaging code it has the reputation that it is not suitable for production applications because data scientists don’t pay enough attention to technical debt within their codebases. Most people think of technical debt as an engineering problem. We choose to make our current work cheaper at the expense of needing to do more work down the road. But when you look closely at the root causes of technical debt they are almost always about interpersonal relationships. Developers have trouble empathizing with other users of their code and so don’t spend the time to make that code easy for future developers to use and understand. In this talk I argue that we should think about technical debt as a social problem because it gives us insight into why it’s so hard to pay back. I then provide a practical roadmap of how to introduce best practices into your data science team.\r\n","content":"Technical debt is a<br>social problem","group":"Room 2","type":"range","style":"color: white; background-color: #D4E3A2b3; border-color: #D4E3A2;"},{"id":"ad69c123-b268-4016-b58a-57f1901bb1ab","start":"2020-01-29 16:46:00","end":"2020-01-29 17:08:00","title":"Category: Case Study\nTitle: R + Tidyverse in Sports\nTime: 04:46PM to 05:08PM\nSpeaker(s): Namita Nandakumar (Philadelphia Eagles, Quantitative Analyst)\n\nThis talk will use a case study, most likely in hockey, to showcase the many ways in which R and the tidyverse can be used to analyze sports data as well as the unique priorities and considerations that are involved in applying statistical tools to sports problems.\r\n","content":"R + Tidyverse in<br>Sports","group":"Room 3","type":"range","style":"color: white; background-color: #2A87BDb3; border-color: #2A87BD;"},{"id":"c3b70a5f-07f8-4762-a830-3e8f9e32831a","start":"2020-01-29 16:46:00","end":"2020-01-29 17:08:00","title":"Category: Learning and Using R\nTitle: Toward a grammar of psychological experiments\nTime: 04:46PM to 05:08PM\nSpeaker(s): Danielle Navarro (University of New South Wales)\n\nWhy does a psychological scientist learn a programming language? While motivations are many and varied the two most prominent are data analysis and data collection. The R programming language is well placed to address the first need, but there are fewer options for programming behavioural experiments within the R ecosystem. The simplest experimental designs can be recast as surveys, for which there are many options, but studies in cognitive psychology, psychophysics or developmental psychology typically require more flexibility. In this talk I outline the design principles behind xprmntr, an R package that provides wrappers to the a javascript library (jsPsych) for constructing web based psychology experiments and uses the plumber package to call server side R code as needed. In doing so, I discuss limitations to the current implementation and what a \"grammar of experiments\" might look like.\r\n","content":"Toward a grammar of<br>psychological<br>experiments","group":"Room 1","type":"range","style":"color: white; background-color: #7C9FD1b3; border-color: #7C9FD1;"},{"id":"f8673901-97c6-4edf-9cf7-e93d77da8fa8","start":"2020-01-29 16:46:00","end":"2020-01-29 17:08:00","title":"Category: Pharma\nTitle: FlatironKitchen: How we overhauled a Frankensteinian SQL workflow with the tidyverse\nTime: 04:46PM to 05:08PM\nSpeaker(s): Nathaniel Phillips (Roche, Senior Data Scientist)\n\nFlatironKitchen: How we overhauled a Frankensteinian SQL workflow with the tidyverse to enable fast, reproducible, elegant analyses of electronic health records.\r\nThe increasing availability of real-world electronic health record (EHR) data is revolutionising how pharma companies are developing Personalized Healthcare (PHC) solutions. However, the scale and complexity of EHR data pose major challenges in deriving fit-for-purpose insights systematically and efficiently. The conventional approach, where siloed programmers write (or copy and paste) thousands of lines of undocumented, untested, unconnected SAS and SQL code for every research project is bad for business and ultimately for patients. Our team threw out the conventional approach and turned to R and the tidyverse. The result is FlatironKitchen, a modern R package enabling end-to-end EHR analyses in a cohesive, user-centric platform. FlatironKitchen allows users to “pipe their way” from database connections, to calculating derived variables, to running statistical analyses, to creating stunning visualisations. All of the technical details are both fully documented and seamlessly automised allowing users to focus on only meaningful functions that are fit-for-purpose to EHR analyses. The result: FlatironKitchen code is so simple it actually tells a step-by-step, human readable story about what the data scientist is doing-- a far cry from the Frankensteinian SQL/SAS code from the past. FlatironKitchen represents the best of both worlds in pharmaceutical data science. It gives expert data scientists a library of unit-tested, customisable functions for implementing existing procedures and designing new ones. Simultaneously, it enables those who are ‘coding insecure’ to -- finally -- work directly with data by reducing barriers. FlatironKitchen’s simple, easy-to-use syntax, combined with its training library of tutorials, vignettes and lessons made possible through RMarkdown has shown itself to be truly empowering. In addition to showcasing FlatironKitchen, we share lessons learned, and give a call to action for other pharma companies to embrace R.\r\n","content":"FlatironKitchen:<br>How we overhauled a<br>Frankensteinian SQL<br>workflow with the","group":"Room 4","type":"range","style":"color: white; background-color: #9591ACb3; border-color: #9591AC;"},{"id":"5b009813-1888-4c1c-bbfc-8e9b91262b25","start":"2020-01-29 16:46:00","end":"2020-01-29 17:08:00","title":"Category: Programming\nTitle: Parallel computing with R using foreach, future, and other packages\nTime: 04:46PM to 05:08PM\nSpeaker(s): Bryan Lewis\n\nSteve Weston's foreach package defines a simple but powerful framework for map/reduce and list-comprehension-style parallel computation in R. One of its great innovations is the ability to support many interchangeable back-end computing systems so that *the same R code* can run sequentially, in parallel on your laptop, or across a supercomputer. Recent new packages like future package define elegant new programming approaches that can use the foreach framework to run across a wide variety of parallel computing systems. This talk introduces the basics of foreach and future packages with examples using a variety of back-end systems including MPI, Redis and R's default parallel package clusters.","content":"Parallel computing<br>with R using<br>foreach, future,<br>and other packages","group":"Room 2","type":"range","style":"color: white; background-color: #D4E3A2b3; border-color: #D4E3A2;"},{"id":"c003961a-ff90-4665-9abb-e663485b7826","start":"2020-01-29 17:09:00","end":"2020-01-29 17:29:00","title":"Category: Case Study\nTitle: Making better spaghetti (plots): Exploring the individuals in longitudinal data with the brolgar pac\nTime: 05:09PM to 05:29PM\nSpeaker(s): Nicholas Tierney (Monash University, Lecturer)\n\nThere are two main challenges of working with longitudinal (panel) data: 1) Visualising the data, and 2) Understanding the model. Visualising longitudinal data is challenging as you often get a \"spaghetti plot”, where a line is drawn for each individual. When overlaid in one plot, it can have the appearance of a bowl of spaghetti. With even a small number of subjects, these plots are too overloaded to be read easily. For similar reasons, it is difficult to relate the model predictions back to the individual and keep the context of what the model means for the individual. For both visualisation, and modelling, it is challenging to capture interesting or unusual individuals, which are often lost in the noise. Better tools, and a more diverse set of grammar and verbs are needed to visualise and understand longitudinal data and models, to capture the individual experiences. In this talk, I introduce the R package, **brolgar** (BRowse over Longitudinal data Graphically and Analytically in R), which provides new tools, verbs, and grammar to identify and summarise interesting individual patterns in longitudinal data. This package extends upon ggplot2 with custom facets, and the new tidyverts time series packages to efficiently explore longitudinal data.\r\n","content":"Making better<br>spaghetti (plots):<br>Exploring the<br>individuals in","group":"Room 3","type":"range","style":"color: white; background-color: #2A87BDb3; border-color: #2A87BD;"},{"id":"63da2ab5-1e68-4bc2-af7b-8f1142cd34b9","start":"2020-01-29 17:09:00","end":"2020-01-29 17:29:00","title":"Category: Learning and Using R\nTitle: R for Graphical Clinical Trial Reporting\nTime: 05:09PM to 05:29PM\nSpeaker(s): Frank Harrell (Vanderbilt University, Professor of Biostatistics)\n\nFor clinical trials a good deal of effort goes into producing both final trial reports and interim reports for data monitoring committees, and experience has shown that reviewers much prefer graphical to tabular reports. Interactive graphical reports go a step further and allow the most important information to be presented by default, while inviting the reviewer to drill down to see other details. The drill-down capability, implemented by hover text using the R plotly package, allows one to almost entirely dispense with tables because the hover text can contain the part of a table that pertains to the reviewer's current focal point in the graphical display, among other things. Also, there are major efficiency gains by having a high-level language for producing common elements of reports related to accrual, exclusions, descriptive statistics, adverse events, time to event, and longitudinal data. This talk will overview the hreport package, which relies on R, RMarkdown, knitr, plotly, Hmisc, and HTML5.  RStudio is an ideal report development environment for using these tools.","content":"R for Graphical<br>Clinical Trial<br>Reporting","group":"Room 1","type":"range","style":"color: white; background-color: #7C9FD1b3; border-color: #7C9FD1;"},{"id":"38bfec49-eddf-47aa-8d13-659296f7d8b4","start":"2020-01-29 17:09:00","end":"2020-01-29 17:29:00","title":"Category: Pharma\nTitle: Using R to Create Reproducible Engineering Test Reports\nTime: 05:09PM to 05:29PM\nSpeaker(s): Ana Alyeska Santos (Biosense Webster, Inc., Quality Engineer I)\n\nEngineers at Biosense Webster, a Johnson and Johnson medical device company that specializes in diagnosing and treating cardiac arrhythmias, write multiple test reports to comply with FDA regulatory standards. These intricate reports require 36 hours of an engineer’s time on average, constraining the engineers from completing investigations and studies in a timely matter. Writing scripts in R that create reproducible reports can significantly reduce the time spent by an engineer creating these reports allowing them to do a much thorough investigation with a larger scope. Through Shiny, engineers could conveniently have their parameters and recorded data processed and stored in a database by accessing a web link and filling out the required information within a user-friendly interface. Upon the generation of the report, accurate and properly formatted test reports, compliant to both the company and FDA regulatory standards, are produced through Rmarkdown and knitr knitting all the outputs with complete data analysis tools such as normality plots and process capability measurements to a word document that follows company required headers, footers, and headings. The reproducible report creation shown in this report can be extended to other types of test reports and protocols. The pilot phase that has been conducted has shown that complete report production has been decreased from 36 hours to an hour.\r\n","content":"Using R to Create<br>Reproducible<br>Engineering Test<br>Reports","group":"Room 4","type":"range","style":"color: white; background-color: #9591ACb3; border-color: #9591AC;"},{"id":"a63f3f87-a6e1-4f63-bc0a-adb664886871","start":"2020-01-29 17:09:00","end":"2020-01-29 17:29:00","title":"Category: Programming\nTitle: Future: Simple Async, Parallel & Distributed Processing in R - What's Next?\nTime: 05:09PM to 05:29PM\nSpeaker(s): Henrik Bengtsson (University of California, San Francisco, Associate Professor)\n\nFuture is a minimal and unifying framework for asynchronous, parallel, and distributed computing in R. It is designed for robustness, consistency, scalability, extendability, and adoptability - all in the spirit of \"developer writes code once, user runs it anywhere\". It is being used in production for high-performance computing and asynchronous UX, among other things. In this talk, I will discuss common feature requests, recent progress we have made, and what is the pipeline.","content":"Future: Simple<br>Async, Parallel &<br>Distributed<br>Processing in R -","group":"Room 2","type":"range","style":"color: white; background-color: #D4E3A2b3; border-color: #D4E3A2;"},{"id":"f84a21b9-ab4f-4886-90f4-42a6f5990f31","start":"2020-01-30 09:00:00","end":"2020-01-30 10:00:00","title":"Category: Keynote\nTitle: Object of type ‘closure’ is not subsettable\nTime: 09:00AM to 10:00AM\nSpeaker(s): Jenny Bryan (RStudio, Software Engineer)\n\nYour first “object of type ‘closure’ is not subsettable” error message is a big milestone for an R user. Congratulations, if there was any lingering doubt, you now know that you are officially programming! Programming involves considerably more troubleshooting and debugging than many of us expected (or signed up for). The ability to solve your own problems is an incredibly powerful stealth skill that is worth cultivating with intention. This talk will help you nurture your inner problem solver, covering both general debugging methods and specific ways to implement them in the R ecosystem.\r\n","content":"Object of type<br>‘closure’ is not<br>subsettable","group":"Room 2","type":"range","style":"color: white; background-color: #0B4947b3; border-color: #0B4947;"},{"id":"9ba940f7-ec0d-432f-8357-73ec0f0a31de","start":"2020-01-30 10:30:00","end":"2020-01-30 10:52:00","title":"Category: Communication\nTitle: Branding and Packaging Reports with R Markdown\nTime: 10:30AM to 10:52AM\nSpeaker(s): Jake Thompson (Accessible Teaching, Learning, and Assessment Systems, Senior Psychometrician)\n\nThe creation of research reports and manuscripts is a critical aspect of the work conducted by organizations and individual researchers. Most often, this process involves copying and pasting output from many different analyses into a separate document. Especially in organizations that produce annual reports for repeated analyses, this process can also involve applying incremental updates to annual reports. It is important to ensure that all relevant tables, figures, and numbers within the text are updated appropriately. Done manually, these processes are often error prone and inefficient. R Markdown is ideally suited to support these tasks. With R Markdown, users are able to conduct analyses directly in the document or read in output from a separate analyses pipeline. Tables, figures, and in-line results can then be dynamically populated and automatically numbered to ensure that everything is correctly updated when new data is provided. Additionally, the appearance of documents rendered with R Markdown can be customized to meet specific branding and formatting requirements of organizations and journals. In this presentation, we will present one implementation of customized R Markdown reports used for Accessible Teaching, Learning, and Assessment Systems (ATLAS) at the University of Kansas. A publicly available R package, ratlas, provides both Microsoft Word and LaTeX templates for different types of projects at ATLAS with their own unique formatting requirements. We will discuss how to create brand-specific templates, as well as how to incorporate the templates into an R package that can be used to unify report creation across an organization. We will also describe other components of branding reports beyond R Markdown templates, including customized ggplot2 themes, which can also be wrapped into the R package. Finally, we will share lessons learned from incorporating the R package workflow into an existing reporting pipeline.\r\n","content":"Branding and<br>Packaging Reports<br>with R Markdown","group":"Room 2","type":"range","style":"color: white; background-color: #C86253b3; border-color: #C86253;"},{"id":"82240a2e-0cd3-48c0-b643-6358ac8bd4f5","start":"2020-01-30 10:30:00","end":"2020-01-30 10:52:00","title":"Category: Medicine\nTitle: Building a Medical Device with R\nTime: 10:30AM to 10:52AM\nSpeaker(s): Ron Keizer (InsightRX, Chief Science Officer)\n\nThe InsightRX precision dosing platform tailors in-patient drug doses to individual patients' characteristics and biomarkers, leveraging pharmacological models of drug metabolism and drug effects. These models are implemented in R, exposed through APIs, and called from a cloud-based web application. The core of our pharmacokinetic/pharmacodynamic simulation functionality is available open source at `github.com/InsightRX/PKPDsim` and `github.com/InsightRX/clinPK`. As a regulated device in Europe (and soon to be in the US) used in over 100 hospitals, the platform is necessarily developed under \"design control\", meaning that strict product planning and engineering practices are required. This has implications for how the application and APIs are developed and deployed, such as strict version control workflows and implementation of rigorous testing procedures. To meet the requirements for high availability and horizontal scaling, we use a combination of Plumber and OpenCPU, hosted on RStudio Connect and AWS Fargate/ECS, which cater to the various needs of the development and production environments.\r\n","content":"Building a Medical<br>Device with R","group":"Room 4","type":"range","style":"color: white; background-color: #A4151Cb3; border-color: #A4151C;"},{"id":"56b9aa0a-8bcc-4367-8300-1830fe7bc48e","start":"2020-01-30 10:30:00","end":"2020-01-30 10:52:00","title":"Category: Visualization\nTitle: The Glamour of Graphics\nTime: 10:30AM to 10:52AM\nSpeaker(s): William Chase (University of Pennsylvania, Data analyst)\n\nI see a lot of ugly charts. This is to be expected as I work with a lot of academics and data scientists, neither of whom have been trained in how to design attractive charts. I myself produced many ugly charts during my years as a research scientist, when the design process basically came down to random tweaking until things \"looked good\". If only I could go back and tell young inexperienced me that there was a better way. In this talk, I will present that better way--a series of design principles that can take any chart from drab to fab. Rather than applying these techniques willy nilly, I will show how they form a layered \"Glamour of Graphics\" that is structured and can be easily applied to any chart. This Glamour of Graphics has some simple implementations in ggplot, where we will replace geoms, aesthetics, and scales with typography, color, and layout. Finally, I will discuss why looks matter when it comes to charts, and how by following the Glamour of Graphics you can design charts that are more persuasive and more accurately perceived.\r\n","content":"The Glamour of<br>Graphics","group":"Room 1","type":"range","style":"color: white; background-color: #7B4534b3; border-color: #7B4534;"},{"id":"4821ea1e-a51e-47d1-b7b8-f34e50043f8c","start":"2020-01-30 10:30:00","end":"2020-01-30 10:52:00","title":"Category: Workflow\nTitle: RMarkdown Driven Development\nTime: 10:30AM to 10:52AM\nSpeaker(s): Emily Riederer (Capital One, Analytics Manager)\n\nRMarkdown enables analysts to engage with code interactively, embrace literate programming, and rapidly produce a wide variety of high-quality data products such as documents, emails, dashboards, and websites. However, RMarkdown is less commonly explored and celebrated for the important role it can play in helping R users grow into developers. In this talk, I will provide an overview of RMarkdown Driven Development: a workflow for converting one-off analysis into a well-engineered and well-designed R package with deep empathy for user needs. We will explore how the methodical incorporation of good coding practices such as modularization and testing naturally evolves a single-file RMarkdown into an R project or package. Along the way, we will discuss big-picture questions like “optimal stopping” (why some data products are better left as single files or projects) and concrete details such as the {here} and {testthat} packages which can provide step-change improvements to project sustainability. \r\n","content":"RMarkdown Driven<br>Development","group":"Room 3","type":"range","style":"color: white; background-color: #61AEACb3; border-color: #61AEAC;"},{"id":"c152e08a-9995-4eab-b1f4-c139203af0ff","start":"2020-01-30 10:53:00","end":"2020-01-30 11:15:00","title":"Category: Communication\nTitle: Don’t repeat yourself, talk to yourself! Repeated reporting in the R universe.\nTime: 10:53AM to 11:15AM\nSpeaker(s): Sharla Gelfand (R and Shiny Developer)\n\nIf you’re responsible for analyses that need updating or repeating on a semi-regular basis, you might find yourself doing the same work over and over again. The principle of \"don’t repeat yourself\" from software engineering motivates us to use functions and packages, the core of repetition in the R universe. For analyses, it can be difficult to know how to use this principle and move beyond \"copying and pasting scripts and changing the data file and the object names and updating the dates and results in RMarkdown\", especially when there’s some element of human intervention required, whether it be for validating assumptions or cleaning artisanal data.  This talk will focus on those next steps, showcasing opportunities to stop repeating yourself and instead anticipate the needs of and communicate effectively with your future self (or the next person with your job!) using project-oriented workflows, clever interactivity, templated analyses, functions, and yes, your own packages.\r\n","content":"Don’t repeat<br>yourself, talk to<br>yourself! Repeated<br>reporting in the R","group":"Room 2","type":"range","style":"color: white; background-color: #C86253b3; border-color: #C86253;"},{"id":"748ff65d-fbbb-45e0-833d-418169cddc58","start":"2020-01-30 10:53:00","end":"2020-01-30 11:15:00","title":"Category: Medicine\nTitle: Development of a web-based clinical decision support application for platelet transfusion management\nTime: 10:53AM to 11:15AM\nSpeaker(s): Justin Juskewitch (Mayo Clinic, Transfusion medicine and clinical informatics fellow)\n\nDevelopment of a web-based clinical decision support application for platelet transfusion management using R and the Tidyverse\r\nBlood product transfusion is a high risk and costly medical procedure. Platelets (blood cells that initiate clotting) are a rare and expensive blood product with a short shelf life. Proper management of platelet transfusions is essential to clinical care, particularly for patients who have developed antibodies against specific platelet types due to pregnancy or past transfusions. By providing platelets that avoid a patient’s known antibodies, improved patient outcomes and better inventory management of a rare blood product are achieved. To address this need, we used R, Tidyverse, and several key packages (Shiny, shinydashboard, dplyr, purrr, httr, officer, flextables, futures) to develop a web-based application (PLTVXM) to help guide platelet inventory selection. PLTVXM queries information on available/pending platelet inventory (and eligible donors) from reports that run in our institutional reporting tool Tableau® via a Tableau Server REST API. Patient antibody and blood type information is securely retrieved from a clinical data lake via an in-house R package (“dart”) and a custom institutional API. The retrieved data is processed by a published algorithm implemented in R and incorporates user input to present sortable tables of patient-specific compatible platelet inventory (and donors) for consideration. The requisite documentation for platelet product reservation or donor recruitment is then autogenerated using institutional form templates. PLTVXM is deployed on an RStudio Connect server which allows seamless integration with our institution’s Active Directory identity management infrastructure. The pilot version of PLTVXM was created by physicians without formal computer programming training in two weeks. After successful demonstration, PLTVXM was approved for clinical validation and future use in our practice. Our experience highlights how R can facilitate creation of dynamic web-based applications for a wide range of business (or clinical) needs.\r\n","content":"Development of a<br>web-based clinical<br>decision support<br>application for","group":"Room 4","type":"range","style":"color: white; background-color: #A4151Cb3; border-color: #A4151C;"},{"id":"d84c6ee3-9cfc-4bd7-bd01-c8f4446d7bff","start":"2020-01-30 10:53:00","end":"2020-01-30 11:15:00","title":"Category: Visualization\nTitle: 3D ggplots with rayshader\nTime: 10:53AM to 11:15AM\nSpeaker(s): Tyler Morgan-Wall (Institute for Defense Analyses, Dr.)\n\nLearn how a single line of code can transform your data visualizations into stunning 3D using the rayshader package. In this talk, I will show how you can use rayshader to create beautiful 3D figures and animations to help promote your research and analyses to the public. Find out how to use principles of cinematography to take users on a 3D tour of your data, scripted entirely within R. Leaving the 3D pie charts in the pantry at home, I will discuss how to build interpretable, engaging, and informative plots using all three dimensions.\r\n","content":"3D ggplots with<br>rayshader","group":"Room 1","type":"range","style":"color: white; background-color: #7B4534b3; border-color: #7B4534;"},{"id":"08421d97-b1e7-4db0-9de2-5701d84c9662","start":"2020-01-30 10:53:00","end":"2020-01-30 11:15:00","title":"Category: Workflow\nTitle: renv: Project Environments to R\nTime: 10:53AM to 11:15AM\nSpeaker(s): Kevin Ushey (RStudio, Inc, Software Engineer)\n\nThe renv package helps you create reproducible environments for your R projects. With renv, you can make your R projects more: Isolated: Installing a new or updated package for one project won’t break your other projects, and vice versa. Portable: Easily transport your projects from one computer to another, even across different platforms. renv makes it easy to install the packages your project depends on. Reproducible: renv records the exact package versions you depend on, and ensures those exact versions are the ones that get installed wherever you go. In this presentation, I'll introduce renv and some of its main workflows.\r\n","content":"renv: Project<br>Environments to R","group":"Room 3","type":"range","style":"color: white; background-color: #61AEACb3; border-color: #61AEAC;"},{"id":"a42a7a38-4446-40ae-ac33-20f211442286","start":"2020-01-30 11:16:00","end":"2020-01-30 11:38:00","title":"Category: Communication\nTitle: How Rmarkdown changed my life\nTime: 11:16AM to 11:38AM\nSpeaker(s): Rob Hyndman (Monash University, Professor of Statistics)\n\nOver the last few years, Rmarkdown seems to have taken over my life, or at least my written communication. These days I use Rmarkdown to maintain my website, write my blog, write textbooks, write academic papers, prepare slides for talks, keep my CV up-to-date, help my students write theses, prepare university policy documents, write letters, prepare exams, write reports for clients, and more. I haven't quite got to the point of using it for shopping lists, but perhaps that's my next Rmarkdown template. I will reflect on the journey in getting to this point, what I've lost and what I've gained. I will also speculate on what might be next in the Rmarkdownification of my life.\r\n","content":"How Rmarkdown<br>changed my life","group":"Room 2","type":"range","style":"color: white; background-color: #C86253b3; border-color: #C86253;"},{"id":"7dc1f6b0-2d79-4cbb-91c8-0e59e50d8f9c","start":"2020-01-30 11:16:00","end":"2020-01-30 11:38:00","title":"Category: Medicine\nTitle: Forecasting Platelet Blood Bag Demand to Reduce Inventory Wastage at the Stanford Blood Center\nTime: 11:16AM to 11:38AM\nSpeaker(s): Qian Zhao (Stanford University, Ph.D. student)\n\nThe Stanford Blood Center collects and distributes blood products to Stanford Hospital. One of these is platelets, a vital clot-forming blood component with a limited shelf life of a few days. Previous work (Guan et al. , 2017) formulated an optimization problem using features aggregated from the available data to solve the problem of reducing waste. An R package was created for a three-day ordering strategy but has not been put into production due to lack of human trust in modelling accuracy. In summer 2019, the Stanford Data Science for Social Good team, decided to make use of additional patient-level data and models to predict platelet consumption rather than relying solely on aggregated data. Modeling the transfusion recipients into different subpopulations allows for finer-grained predictions on a patient level. We make extensive use of R packages, such as the tidyverse and R Shiny, to conduct exploratory data analysis, build models, and create a user-intuitive dashboard. The Shiny dashboard is designed to display consumption predictions aggregated across all models, consumption predictions for each subpopulation, and historical performance of the model, thereby serving as a valuable tool in building the trust necessary for adopting the algorithmic ordering strategies. Reference Guan, L., Tian, X., et al. (2017). “Big data modeling to predict platelet usage and minimize wastage in a tertiary care system.” PNAS (43) 114: 11368 - 11373. Retrieved from: www.pnas.org/cgi/doi/10.1073/pnas.1714097114\r\n","content":"Forecasting<br>Platelet Blood Bag<br>Demand to Reduce<br>Inventory Wastage","group":"Room 4","type":"range","style":"color: white; background-color: #A4151Cb3; border-color: #A4151C;"},{"id":"1ba2254d-cfa9-403d-9e43-bd58014f9c9b","start":"2020-01-30 11:16:00","end":"2020-01-30 11:38:00","title":"Category: Visualization\nTitle: Designing Effective Visualizations\nTime: 11:16AM to 11:38AM\nSpeaker(s): Miriah Meyer (University of Utah, Professor)\n\n","content":"Designing Effective<br>Visualizations","group":"Room 2","type":"range","style":"color: white; background-color: #7B4534b3; border-color: #7B4534;"},{"id":"e7677084-4afd-4f68-8ced-2b0a159f56a0","start":"2020-01-30 11:16:00","end":"2020-01-30 11:38:00","title":"Category: Workflow\nTitle: RStudio 1.3 Sneak Preview\nTime: 11:16AM to 11:38AM\nSpeaker(s): Jonathan McPherson (RStudio, Software Engineer)\n\nRStudio 1.3, currently available as a preview release, includes a number of new capabilities that will help you be more productive in R. It's also more configurable, accessible, and flexible. In this talk, you'll learn to take advantage of these new tools.\r\n","content":"RStudio 1.3 Sneak<br>Preview","group":"Room 3","type":"range","style":"color: white; background-color: #61AEACb3; border-color: #61AEAC;"},{"id":"adc756af-1e58-459f-8a95-9f06b3b341d0","start":"2020-01-30 11:39:00","end":"2020-01-30 11:59:00","title":"Category: Communication\nTitle: One R Markdown Document, Fourteen Demos\nTime: 11:39AM to 11:59AM\nSpeaker(s): Yihui Xie (RStudio, Software Engineer and Data Scientist)\n\nR Markdown is a document format based on the R language and Markdown to intermingle computing with narratives in the same document. With this simple format, you can actually do a lot of things. For example, you can generate reports dynamically (no need to cut-and-paste any results because all results can be dynamically generated from R), write papers and books, create websites, and make presentations. In this talk, I'll use a single R Markdown document to give demos of the R packages rmarkdown, bookdown for authoring books (https://bookdown.org), blogdown for creating websites (https://github.com/rstudio/blogdown), rticles for writing journal papers (https://github.com/rstudio/rticles), xaringan for making slides (https://github.com/yihui/xaringan), flexdashboard for generating dashboards (https://github.com/rstudio/flexdashboard), learnr for tutorials (https://github.com/rstudio/learnr), rolldown for storytelling (https://github.com/yihui/rolldown), and the integration between Shiny and R Markdown. To make the best use of your time during the presentation, I recommend you to take a look at the rmarkdown website in advance: https://rmarkdown.rstudio.com.\r\n","content":"One R Markdown<br>Document, Fourteen<br>Demos","group":"Room 2","type":"range","style":"color: white; background-color: #C86253b3; border-color: #C86253;"},{"id":"d8acadca-5e06-49b9-8372-ac0ef1c9a74e","start":"2020-01-30 11:39:00","end":"2020-01-30 11:59:00","title":"Category: Medicine\nTitle: Shiny New Things: Using R to Bridge the Gap in EMR Reporting\nTime: 11:39AM to 11:59AM\nSpeaker(s): Brendan Graham (Children's Hospital of Philadelphia, Healthcare Data Analyst)\n\nElectronic Medical Records (EMRs) are a treasure trove of information, but tend to fall disappointingly short when it comes to visualizing and reporting data in a user friendly and intuitive manner. Building reports in an EMR can be a frustrating experience; the developer is at the mercy of how the data is stored within the EMR and the available EMR reporting tools can be bland and uninspiring. But reporting on data in the EMR doesn't have to be this way! Combining the data-rich EMR with R's robust reporting capabilities benefits both developers and consumers of data. This talk will describe how a cross-departmental project team uses an internal R package, RMarkdown reports scheduled via R Studio Connect, and an interactive flexdashboard app to quickly implement solutions to gaps in the reporting capabilities of the EMR. The flexibility of R relative to EMR reporting tools facilitates a design thinking approach to reporting allowing for more user input, customization and quick iteration. Furthermore, the web-based app we developed is able to be embedded within the EMR itself allowing for a more streamlined workflow.\r\n","content":"Shiny New Things:<br>Using R to Bridge<br>the Gap in EMR<br>Reporting","group":"Room 4","type":"range","style":"color: white; background-color: #A4151Cb3; border-color: #A4151C;"},{"id":"422c5e4a-aff6-4277-bbff-71f9a34e804f","start":"2020-01-30 11:39:00","end":"2020-01-30 11:59:00","title":"Category: Visualization\nTitle: Tidyverse 2019-2020\nTime: 11:39AM to 11:59AM\nSpeaker(s): Hadley Wickham (RStudio, Chief Scientist)\n\n","content":"Tidyverse 2019-2020","group":"Room 1","type":"range","style":"color: white; background-color: #7B4534b3; border-color: #7B4534;"},{"id":"34e68e07-d564-4612-8025-bf112576d6a8","start":"2020-01-30 11:39:00","end":"2020-01-30 11:59:00","title":"Category: Workflow\nTitle: Using Jupyter with RStudio Server Pro\nTime: 11:39AM to 11:59AM\nSpeaker(s): Karl Feinauer (RStudio, Software Engineer)\n\nThis talk is for R admins who want to learn how to set up Jupyter notebooks on RStudio Server Pro. We'll cover prerequisites, basic configuration, best practices for management, Jupyter Lab, and more.\r\n","content":"Using Jupyter with<br>RStudio Server Pro","group":"Room 3","type":"range","style":"color: white; background-color: #61AEACb3; border-color: #61AEAC;"},{"id":"df93fafe-1d66-46be-839b-aa653ff36d4f","start":"2020-01-30 13:00:00","end":"2020-01-30 13:22:00","title":"Category: Modeling\nTitle: MLOps for R with Azure Machine Learning\nTime: 01:00PM to 01:22PM\nSpeaker(s): David Smith (Microsoft, Cloud Advocate)\n\nAzure Machine Learning service (Azure ML) is Microsoft’s cloud-based machine learning platform that enables data scientists and their teams to carry out end-to-end machine learning workflows at scale. With Azure ML's new open-source R SDK and R capabilities, you can take advantage of the platform’s enterprise-grade features to train, tune, manage and deploy R-based machine learning models and applications. In this talk, the attendees will learn how to: •Carry out ML workflows using the authoring experience of their choice, from no-code to code-first options that include Azure ML’s drag-and-drop visual interface for defining workflows and RStudio Server on the Data Science Instance, a hosted VM workstation, for using the Azure ML R SDK from the RStudio browser-based interface. •Use the Azure ML R SDK to manage cloud resources and train, hyperparameter tune, and log and visualize metrics for their models at scale on Azure compute. •Build ML Pipelines in R for defining and orchestrating reusable and reproducible ML workflows. •Deploy, manage, and monitor their R ML models and applications as web services on Azure Container Instance and Azure Kubernetes Service, with an emphasis on robust DevOps and CI/CD for orchestrating and streamlining their end-to-end data science development lifecycle.\r\n","content":"MLOps for R with<br>Azure Machine<br>Learning","group":"Room 1","type":"range","style":"color: white; background-color: #A0271Bb3; border-color: #A0271B;"},{"id":"31bb43be-554e-4488-81b3-8e07c7ba33c9","start":"2020-01-30 13:00:00","end":"2020-01-30 13:22:00","title":"Category: Organizational Thinking\nTitle: Small Team, Big Value: Using R to Design Visualizations\nTime: 01:00PM to 01:22PM\nSpeaker(s): Ian Lyttle (Schneider Electric)\n\nMany R users can feel isolated due to the prevalence of Python or Tableau at their institutions. This talk will focus on how we use R to develop reference implementations of visualizations (using ggplot2), and to develop corporate-themed color maps (using the colorspace package) to bring value to the entire institution. Color maps can be translated into variety of formats, for Tableau, Qlik Sense, d3, etc., and deployed independently from R. For visualizations, our goal is to translate ggplot2 objects to Vega-Lite specifications, using a package we are developing: ggvega. Vega-Lite visualizations are web-native, and are rendered independently from R. Specifications can be designed to be extensible to new data, allowing them serve as templates, to be deployed and updated for use outside of R. Of course, despite isolation within an institution, our work with the larger R open-source communities provides a foundation on which to build; in fact, we have a lot of company and are having a lot of fun.\r\n","content":"Small Team, Big<br>Value: Using R to<br>Design<br>Visualizations","group":"Room 3","type":"range","style":"color: white; background-color: #8592A4b3; border-color: #8592A4;"},{"id":"f34b33b5-37c3-4873-8712-63a4c80e4a29","start":"2020-01-30 13:00:00","end":"2020-01-30 13:22:00","title":"Category: Programming\nTitle: Auto-magic package development: Building an R API for building Vega-Lite Specs\nTime: 01:00PM to 01:22PM\nSpeaker(s): Alicia Schep (Outlier AI, Senior Data Scientist)\n\nVega-lite is a high-level grammar of interactive graphics implemented in Javascript; it renders interactive visualizations in the browser based on a JSON specification. In Python and Javascript, the Altair and vega-lite-api packages have demonstrated how the development of APIs to build Vega-Lite graphics can be partially automated based on the Vega-Lite JSON schema, which describes the required format for a Vega-Lite JSON specification. This talk will describe the development of the ‘vlbuildr’ package for building Vega-Lite specifications in R and the ‘vlmetabuildr’ package for building the ‘vlbuildr’ package. The ‘vlbuildr’ package seeks to provide a pipe-friendly, “R-like” functional interface for building up simple to complex specifications for Vega-Lite graphics, which can in turn be rendered as an HtmlWidget by the ‘vegawidget’ R package. Building such an API in a fully automated way from the Vega-Lite schema presents considerable challenges, so the approach taken here was to rely on partial automation. Human judgement dictates the basic contours of the API, such as what groups of functions to include and how various types of building blocks will go together. The part that is automated is filling in many details such as the different variants of a group of functions, the exact parameters needed for each function, and the documentation of those parameters -- the parts that would be extremely tedious to port over!\r\n","content":"Auto-magic package<br>development:<br>Building an R API<br>for building","group":"Room 4","type":"range","style":"color: white; background-color: #D4E3A2b3; border-color: #D4E3A2;"},{"id":"135530e9-722e-4889-9b2f-30f09bbfbdfa","start":"2020-01-30 13:00:00","end":"2020-01-30 13:22:00","title":"Category: ggplot2\nTitle: Best practices for programming with ggplot2\nTime: 01:00PM to 01:22PM\nSpeaker(s): Dewey Dunnington (Dalhousie University, Ph.D. Candidate)\n\nThe ggplot2 package is widely acknowledged as a powerful, dynamic, and easy-to-learn graphics framework when used in an interactive environment. Using ggplot2 in a package or Shiny app environment adds several constraints which are sometimes circumvented using ggplot2 behaviour that may change in the future. Some best practices include (1) using the `.data` pronoun to refer to the layer data within `aes()` and `vars()` instead of the original variable name, (2) ensuring that `plot()` methods that use ggplot2 explicitly `print()` one or more ggplot objects, (3) defining extension themes that modify a complete theme within ggplot2 (like `theme_gray()`), and (4) testing graphical output using the vdiffr package. Collectively, these practices result in better error messages with unexpected user input and ensure compatibility with most versions of ggplot2, including those to come in the future.\r\n","content":"Best practices for<br>programming with<br>ggplot2","group":"Room 2","type":"range","style":"color: white; background-color: #67718Fb3; border-color: #67718F;"},{"id":"9e5a0716-e5cb-41d9-8b74-d243e6cba9f7","start":"2020-01-30 13:23:00","end":"2020-01-30 13:45:00","title":"Category: Modeling\nTitle: Totally Tidy Tuning Techniques\nTime: 01:23PM to 01:45PM\nSpeaker(s): Max Kuhn (RStudio, Applied Machine Learning)\n\nMany models have structural parameters that cannot be directly estimated from the data. These tuning parameters can have a significant effect on model performance and require some mechanism for finding reasonable values. The tune and workflow packages enable tidymodels users to optimize these parameters using a variety of efficient grid search methods as well as with iterative search techniques (such as Bayesian optimization).\r\n","content":"Totally Tidy Tuning<br>Techniques","group":"Room 1","type":"range","style":"color: white; background-color: #A0271Bb3; border-color: #A0271B;"},{"id":"b76fc6c2-3d63-4006-b5f4-bc6b5ef862be","start":"2020-01-30 13:23:00","end":"2020-01-30 13:45:00","title":"Category: Organizational Thinking\nTitle: UnicoRns are real\nTime: 01:23PM to 01:45PM\nSpeaker(s): Travis Gerke (Moffitt Cancer Center, Scientific Director of Collaborative Data Services)\n\nCommon advice from experienced data scientists to job-seekers is to avoid job postings that describe a \"data science unicorn\": someone who has experience performing an unrealistically large array of technical and business-related job duties. Seeking a unicorn is viewed as a potential indicator that the company fails to understand their data science needs, and that new hires will not be poised for success due to lacking support and resources [Robinson &amp; Nolis, 2019]. The R language, particularly when used with RStudio products, has evolved to enable production-level activities in the areas of data wrangling, reporting/dashboarding, database/software engineering, machine learning, and web application development. It is increasingly plausible that a data scientist will be able to efficiently perform a wide variety of job functions with experience only in a single language (R). Indeed, even entry level R users may tread into \"unicorn\" territory. Current standards for data scientist job descriptions and salaries do not accommodate this nuance, leaving both job-seekers and hiring managers unable to distinguish job requirements which should be read as warning signs from listings which are idyllic matches for the modern R unicorn. In this talk, we present data aggregated from several large compensation analytics companies which summarize current benchmarks for data science job descriptions and corresponding salary ranges. We then suggest job description language to target modern R users, considering both job duty compatibility and job post findability. These descriptions are presented with likely salary range pairings. Attention is given to deviations from traditional degree requirements, years of experience, and demands for multiple programming language literacy which may lack relevance for the R unicorn. Our overarching goal is to provide job description templates which encourage optimal matchmaking between R job seekers and organizations in need of their talents.\r\n","content":"UnicoRns are real","group":"Room 3","type":"range","style":"color: white; background-color: #8592A4b3; border-color: #8592A4;"},{"id":"23129cb7-1186-49c3-9287-9bf9fd22b25f","start":"2020-01-30 13:23:00","end":"2020-01-30 13:45:00","title":"Category: Programming\nTitle: Bridging the gap between SQL and R: Introducing queryparser and tidyquery\nTime: 01:23PM to 01:45PM\nSpeaker(s): Ian Cook (Cloudera, Curriculum Developer)\n\nLike it or not, SQL is the closest thing we have to a universal language for working with structured data. Celebrating its 50th birthday in 2020, SQL today integrates with thousands of applications and has millions of users worldwide. Data analysts using SQL represent a large audience of potential R users motivated to expand their data science skills. But learning R can be frustrating for SQL users. One major frustration is the inability to directly query R data frames with SQL SELECT statements. Eager to use R for tasks that are not possible with SQL (like data visualization and machine learning), these users are dismayed to find that they must first learn an unfamiliar syntax for data manipulation. The popularity of the sqldf package (which automatically exports an R data frame into an embedded database, then runs a SQL query on it) demonstrates this frustration. But now there is a way to directly query an R data frame without moving the data out of R. In this talk, I introduce tidyquery, a new R package that runs SQL queries directly on R data frames. tidyquery is powered by dplyr and by queryparser, a new pure-R, no-dependency SQL query parser.\r\n","content":"Bridging the gap<br>between SQL and R:<br>Introducing<br>queryparser and","group":"Room 4","type":"range","style":"color: white; background-color: #D4E3A2b3; border-color: #D4E3A2;"},{"id":"d2148603-58e1-4d62-ae8a-cfc267028184","start":"2020-01-30 13:23:00","end":"2020-01-30 13:45:00","title":"Category: ggplot2\nTitle: Spruce up your ggplot2 visualizations with formatted text\nTime: 01:23PM to 01:45PM\nSpeaker(s): Claus Wilke (The University of Texas at Austin, Professor of Integrative Biology)\n\nThe ggtext package provides various functions to add formatted text to ggplot2 figures, both in the form of plot or axis labels and in the form of text labels or text boxes inside the plot panel. Text formatting can be achieved through a small subset of markdown, HTML, and CSS directives. Features currently supported include italics, bold, super- and sub-script, as well as changing font size, font family, and color. Basic support for adding images to formatted text is also available.\r\n","content":"Spruce up your<br>ggplot2<br>visualizations with<br>formatted text","group":"Room 2","type":"range","style":"color: white; background-color: #67718Fb3; border-color: #67718F;"},{"id":"a401221d-297b-432f-b612-ed488632e150","start":"2020-01-30 13:46:00","end":"2020-01-30 14:08:00","title":"Category: Modeling\nTitle: Neural Networks for Longitudinal Data Analysis\nTime: 01:46PM to 02:08PM\nSpeaker(s): Sydeaka Watson (Korelasi Data Insights / Elicit Insights, Senior Data Scientist)\n\nLongitudinal data (or panel data) arise when observations are recorded on the same individuals at multiple points in time. For example, a longitudinal baseball study might track individual player characteristics (team affiliation, age, height, weight, etc.) and outcomes (batting average, stolen bases, runs, strikeouts, etc.) over multiple seasons, where the number of seasons could vary across players. Neural network frameworks such as Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs) can flexibly accommodate this data structure while preserving and exploiting temporal relationships. In this presentation, we highlight the use of neural networks for longitudinal data analysis with tensorflow and keras in R.\r\n","content":"Neural Networks for<br>Longitudinal Data<br>Analysis","group":"Room 1","type":"range","style":"color: white; background-color: #A0271Bb3; border-color: #A0271B;"},{"id":"e12072bb-806d-4f62-92e1-fd1849191693","start":"2020-01-30 13:46:00","end":"2020-01-30 14:08:00","title":"Category: Organizational Thinking\nTitle: Data Science in Meatspace\nTime: 01:46PM to 02:08PM\nSpeaker(s): BenJoaquin Gouverneur (Plenty Unlimited, Inc., Manager, Datalab)\n\nThe Data Science community is dominated by folks doing amazing work with data that starts in and never leaves **cyberspace**. This talk is about best paractices and playbooks for doing data science that involves **meatspace** (the opposite of cyberspace) and why R is such a great language for working with data that originated in the physical world. While the concrete examples in this talk will mostly come from the **manufacturing** space, where I have the most experience, I believe the themes are relevant to many meatspace workflows. We'll talk through effective playbooks that can help you navigate common tasks throughout the life-cycle of a project. We’ll also weave in how R’s glorious package ecosystem, including `tidyverse`, can be combined with other languages like `python`, and with enterprise products like **RStudio Connect** to great effect. Specifically, we'll discuss practices in these areas: * best practices for **data collection** in meatspace * the importance of quantifying **measurement system error** * collecting the correct data for training **computer vision** models * the rarely discussed cost of **maintaining models** in production\r\n","content":"Data Science in<br>Meatspace","group":"Room 3","type":"range","style":"color: white; background-color: #8592A4b3; border-color: #8592A4;"},{"id":"a01cabb8-3e45-451b-a13d-8904abede0c9","start":"2020-01-30 13:46:00","end":"2020-01-30 14:08:00","title":"Category: Programming\nTitle: List-columns in data.table: Reducing the cognitive and computational burden when working with comple\nTime: 01:46PM to 02:08PM\nSpeaker(s): Tyson Barrett (Utah State University, Research Assistant Professor)\n\nThe use of list-columns in data frames and tibbles is well documented (e.g. Bryan, 2018), providing a cognitively efficient way to organize results of complex data (e.g. several statistical models, groupings of text, data summaries, or even graphics) with corresponding data. For example, one can store student information within classrooms, player information within teams, or analyses within groups. This allows the data to be of variable sizes without overly complicating or adding redundancies to the structure of the data. In turn, this can improve the reliability to appropriately analyze the data. Because of its efficiency and speed, being able to use data.table to work with list-columns would be beneficial in many data contexts (e.g. to reduce memory usage in large data sets). Herein, I demonstrate how one can create list-columns in a data table using the by argument in data.table and purrr::map(). I compare the behavior of the data.table approaches to the dplyr::group_nest() function and tidyr::unnest(), two of the several powerful tidyverse nesting and unnesting functions. Results using bench::mark() show the speed and efficiency of using data.table to work with list-columns.\r\n","content":"List-columns in<br>data.table:<br>Reducing the<br>cognitive and","group":"Room 4","type":"range","style":"color: white; background-color: #D4E3A2b3; border-color: #D4E3A2;"},{"id":"66b0d4a2-35ec-44be-92f2-ab8272ee34cf","start":"2020-01-30 13:46:00","end":"2020-01-30 14:08:00","title":"Category: ggplot2\nTitle: The little package that could: taking visualizations to the next level with the scales package\nTime: 01:46PM to 02:08PM\nSpeaker(s): Dana Seidel (Plenty Unlimited, Senior Data Scientist)\n\nPrecise axes, proper data transformation, and informative visual data mappings are critical components to any polished visualization. The scales package, the unsung hero behind ggplot2’s scale_* infrastructure, includes functions to help any R user manipulate and polish their visualizations. In this presentation, we will explore the functionality of this small but mighty package: demonstrating its functions for polishing guides, e.g. breaks and labels, managing data transformations, and for mapping aesthetic palettes to data.\r\n","content":"The little package<br>that could: taking<br>visualizations to<br>the next level with","group":"Room 2","type":"range","style":"color: white; background-color: #67718Fb3; border-color: #67718F;"},{"id":"a908e1ea-a021-4a4a-9144-539f8d21c5af","start":"2020-01-30 14:09:00","end":"2020-01-30 14:29:00","title":"Category: Modeling\nTitle: Stochastic Block Models with R: Statistically rigerous clusting with rigorous code\nTime: 02:09PM to 02:29PM\nSpeaker(s): Nick Strayer (Vanderbilt University, PhD Candidate)\n\nOften a machine learning research project starts with brainstorming, continues to one-off scripts while an idea forms, and finally, a package is written to disseminate the product. In this talk, I will share my experience rethinking this process by spreading the package writing across the whole process. While there are cognitive overheads involved with setting up a package framework, I will argue that these overheads can serve as a scaffolding for not only good code but robust research practices. The result of this experiment is the SBMR package: a native R package written to fit and investigate the results of Bipartite Stochastic Block Models that forms the backbone of my PhD dissertation. By going over the ups and downs of this process, I hope to leave the audience with inspiration for moving the package writing process closer to the start of their projects and melding research and code more closely to improve both.","content":"Stochastic Block<br>Models with R:<br>Statistically<br>rigerous clusting","group":"Room 1","type":"range","style":"color: white; background-color: #A0271Bb3; border-color: #A0271B;"},{"id":"c6ca8a39-9bf4-4e2d-97f2-a6bb0f81ca67","start":"2020-01-30 14:09:00","end":"2020-01-30 14:29:00","title":"Category: Organizational Thinking\nTitle: Value in Data Science Beyond Models in Production\nTime: 02:09PM to 02:29PM\nSpeaker(s): Eduardo Ariño de la Rubia\n\nML in production is one of the most obvious ways that data science organizations create value in business. However, these models are at the very end of a long story of how quantitative research changes and enhances organizations. In this talk I will discuss how I have found DS organization to be truly transformative outside of ML in the loop. Bio: Eduardo Ariño de la Rubia is a DS manager and educator. He loves R and RStudio. He has a Masters in Negotiation, Conflict Resolution and Peacebuilding, which is probably the most useful training he could have received.\r\n","content":"Value in Data<br>Science Beyond<br>Models in<br>Production","group":"Room 3","type":"range","style":"color: white; background-color: #8592A4b3; border-color: #8592A4;"},{"id":"6ad3db7d-89ab-4c72-aeac-e228ce58098e","start":"2020-01-30 14:09:00","end":"2020-01-30 14:29:00","title":"Category: Programming\nTitle: Advances in tidyeval\nTime: 02:09PM to 02:29PM\nSpeaker(s): Lionel Henry (RStudio, Advances in tidyeval)\n\nIn tidyverse grammars such as dplyr you can refer to the columns in your data frames as if they were objects in the workspace. This syntax is optimised for interactivity and is a great fit for data analysis, but it makes it harder to write functions and reuse code. In this talk we present some advances in the tidy eval framework that make it easier to program around tidyverse pipelines without having to learn a lot of theory.\r\n","content":"Advances in<br>tidyeval","group":"Room 4","type":"range","style":"color: white; background-color: #D4E3A2b3; border-color: #D4E3A2;"},{"id":"4b9a8f5f-7916-4232-86ea-ba308cb61bbf","start":"2020-01-30 14:09:00","end":"2020-01-30 14:29:00","title":"Category: ggplot2\nTitle: Extending your ability to extend ggplot2\nTime: 02:09PM to 02:29PM\nSpeaker(s): Thomas Lin Pedersen (RStudio, Software Engineer)\n\nThe ggplot2 package continue to be one of the most used frameworks for producing graphics in R. While being extremely flexible, the package itself can be constrained by the different types of graphic elements and statistic transformations available. Instead of continuing to add new features, the development in recent years have focused on making ggplot2 extensible by other packages, thus distributing development and maintenance. Despite the best of intentions, ggplot2 can feel daunting to extend, due unusual idiosyncrasies, a foreign object system, and a partly obscured rendering model. This talk intend to remove the mystery of extending ggplot2, by describing the basic ways that it can be extended and showcasing a couple of simple extensions that can be build with very little code. Lastly, it will include discussions of some best practices and gotchas that may come in handy when you start out.\r\n","content":"Extending your<br>ability to extend<br>ggplot2","group":"Room 2","type":"range","style":"color: white; background-color: #67718Fb3; border-color: #67718F;"},{"id":"895592d5-b93e-487c-bcde-e033b9367411","start":"2020-01-30 14:45:00","end":"2020-01-30 14:50:00","title":"Category: Lightning Talks\nTitle: Making a tidy dress\nTime: 02:45PM to 02:50PM\nSpeaker(s): Amelia McNamara (University of St Thomas, Assistant Professor of Computer & Information Sciences)\n\nAfter at least a year of dreaming about it, I finally produced the #rstats/#tidyverse dress of my dreams. This involved designing fabric, getting it custom printed, making a pattern from an existing garment, and sewing the dress. (https://twitter.com/AmeliaMN/status/1162359039784673282?s=20) I learned a lot of useful lessons during this project, including \"do unit tests\" (make a practice dress) and \"document your work\" (get your BFF to take pictures of you).\r\n","content":"Making a tidy dress","group":"Room 3","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"1b3d95dc-dbe6-4d44-9c43-7c797b4310be","start":"2020-01-30 14:45:00","end":"2020-01-30 14:50:00","title":"Category: Lightning Talks\nTitle: `livecode`: broadcast your live coding sessions from and to RStudio\nTime: 02:45PM to 02:50PM\nSpeaker(s): Colin Rundel (University of Edinburgh, Lecturer)\n\nIn this talk we will demonstrate `livecode`, a new R package for broadcasting code for live code demonstrations. This package implements a simple webserver (using `httpuv`) to dynamically publishes the content of a code file (i.e. `.R` or `.Rmd`) as you edit it live. This enables your students to have near realtime access to your code as you write it. The broadcast file can be viewed with any webbrowser but the package is specifically designed to be used within RStudio leveraging its builtin viewer. This gives students have direct access to the shared code within the IDE, allowing direct copying into their own source files and/or the console and thereby improving their ability to interact and experiment with your code.\r\n","content":"`livecode`:<br>broadcast your live<br>coding sessions<br>from and to RStudio","group":"Room 2","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"8a1f808a-2276-4e26-9d5f-a51c8d660b11","start":"2020-01-30 14:45:00","end":"2020-01-30 15:30:00","title":"Category: Panel\nTitle: Career Advice for Data Scientists\nTime: 02:45PM to 03:30PM\nSpeaker(s): Jen Hecht (RStudio, VP of People Operations)\n\n","content":"Career Advice for<br>Data Scientists","group":"Room 1","type":"range","style":"color: white; background-color: #C16237b3; border-color: #C16237;"},{"id":"9b2c7c13-3be7-4c1e-a3dc-16c90c3e83ae","start":"2020-01-30 14:50:00","end":"2020-01-30 14:55:00","title":"Category: Lightning Talks\nTitle: A high school student’s journey to bring R into the classroom.\nTime: 02:50PM to 02:55PM\nSpeaker(s): Jay Campanell (Liberal Arts and Sciences Academy)\n\nMy 8th grade capstone project introduced me to R. The project was a data visualization about breakfast tacos. I used R and other web based tools. My lightning talk will focus on my experience about using R for class projects and getting the support from my parents to help integrate R into the classroom. I will show how students can get started when they have no clue on how to use R. I will talk about the project’s toolkit which includes RStudio cloud, Google sheets, chomebook, measurement tools, my phone and how R is being used in my school.\r\n","content":"A high school<br>student’s journey<br>to bring R into the<br>classroom.","group":"Room 2","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"d98ac3da-c488-470f-ab68-1a311a2fc728","start":"2020-01-30 14:50:00","end":"2020-01-30 14:55:00","title":"Category: Lightning Talks\nTitle: Datasets in Reproducible Research with 'pins'\nTime: 02:50PM to 02:55PM\nSpeaker(s): Javier Luraschi (RStudio, Software Engineer)\n\nOpen source code is an essential piece in making science reproducible. Tools like 'rmarkdown' and GitHub facilitate running and sharing outcomes with colleagues and with the broad scientific community at large. However, it is less clear what tools should be used to retrieve, store and share datasets; while it is possible to make datasets part of your workflows today, it is usually hard and we are often left with manually sharing or downloading links to datasets. Not only that, but it's also hard to share or discover datasets. In this talk we will introduce for the first time the 'pins' package. A package designed to: pin, discover and share resources. Meaning that, you can use 'pins' to simplify your data science workflows by easily fetching resources from GitHub, Kaggle, CRAN and RStudio Connect. We will present a 'pin' as a generic resource that can contain tabular datasets like CSVs, unstructured data like JSON files, image archives as ZIP files and so on. This talk will be highly interactive showing you how to get started by installing 'pins' from CRAN, retrieve and cache resources, share and discover useful and fun data resources to improve and enhance your day-to-day workflows.\r\n","content":"Datasets in<br>Reproducible<br>Research with<br>'pins'","group":"Room 3","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"d6f33f06-1b40-4d6b-9c16-4719c3987023","start":"2020-01-30 14:55:00","end":"2020-01-30 15:00:00","title":"Category: Lightning Talks\nTitle: Course Material Creation in the R Ecosystem\nTime: 02:55PM to 03:00PM\nSpeaker(s): Kelly Bodwin (California Polytechnic State University - San Luis Obispo, Assistant Professor of Statistics)\n\nIn this talk, I will introduce a suite of three packages designed to aid course material creation in R: {demoR} for displaying code in knitted R Markdown with custom highlighting and formatting; {shindig} for shortcuts to creating simple educational Shiny apps; and {curricular} for easy creation of syllabi, homework exercises, exams, etc. Together, we will explore how these new tools - in conjunction with other existing resources - have been used to create a clean and consistent ecosystem for my R-based Introductory Statistics course. I will share some metrics on student outcomes, as well as my own experiences with the advantages and challenges in building the course.\r\n","content":"Course Material<br>Creation in the R<br>Ecosystem","group":"Room 2","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"9e699e37-317e-4094-8180-ee8088894a8f","start":"2020-01-30 14:55:00","end":"2020-01-30 15:00:00","title":"Category: Lightning Talks\nTitle: Becoming an R blogger\nTime: 02:55PM to 03:00PM\nSpeaker(s): Rebecca Barter (UC Berkeley)\n\nBlogging is an excellent way to learn, improve your communication skills, and gain exposure in the R and data science communities. In this talk, I will discuss how and why I started blogging, and why you should too. I will guide you through choosing topics, writing your blog using RStudio and blogdown, hosting it on netlify, and sharing your blog with the world. This talk is for you if you've wanted to start a blog on R, data science, or to showcase your data analyses, but don't know where to start.\r\n","content":"Becoming an R<br>blogger","group":"Room 3","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"b4794b73-bf31-4c8f-8d4a-f3459a6b048c","start":"2020-01-30 15:00:00","end":"2020-01-30 15:05:00","title":"Category: Lightning Talks\nTitle: Data Science for Software Engineers: busting software myths with R\nTime: 03:00PM to 03:05PM\nSpeaker(s): Yim Register (RStudio/University of Washington)\n\nThe software engineering world is full of claims about best practices, languages, packages, styles, and workflows, but most software engineering students are never taught how to find, read, and interpret actual evidence on those topics. Is agile development really the secret to success? Do some languages actually cause more defects than others? This talk describes a series of meaningful lessons that explore research in software engineering for the beginner R programmer by teaching students to interpret and replicate research findings while learning meaningful results for their field in addition to common statistical methods. The lessons serve as a primer for software engineers to participate in a data-driven society; from advertising and business to combating misinformation and helping user experience.\r\n","content":"Data Science for<br>Software Engineers:<br>busting software<br>myths with R","group":"Room 2","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"e4dba08a-1902-4187-a5aa-0a5975079248","start":"2020-01-30 15:00:00","end":"2020-01-30 15:05:00","title":"Category: Lightning Talks\nTitle: Mexican electoral quick count night with R\nTime: 03:00PM to 03:05PM\nSpeaker(s): Maria Ortiz Mancera (CONABIO, Advisor)\n\nIn Mexico the elections take place on a Sunday, and the official results are presented a week later. To prevent unjustified victory claims during that period the electoral authority organizes a quick count the same night of the election. The quick count consists in selecting a random sample of the polling stations and estimating the percentage of votes in favor of each candidate. With highly competitive electoral processes the quick count has become very important, the rapidity and precision of its results auspicious an environment of trust, and it serves as a tool against fraud. In this application reproducibility is very important. On the scientific side, it is crucial to examine the veracity and robustness of the conclusions of the methodologies. However, in this case, reproducibility is more important still, as it helps to achieve transparency in the electoral procedure. Anyone can download the sample and compute the same results that were announced the night of the election. This transparency fosters trust in institutions and gives legitimacy to the outcome of the quick count. We believe that developing an R package with detailed vignettes made the procedure accessible for the public. The package also facilitated code development and estimation on the election night, when the models were run with partial samples every five minutes, for three different state elections and for the presidential election. Our models were one of 9 different approaches to do the estimation and yet our code is the only publicly available, we are championing for more openness on procedures by sharing our experience. As for the model we developed Bayesian hierarchical models that include demographic and geographic covariates, the purpose of the models is to reduce the biases associated to such covariates due to the fact that complete samples are rarely available to publish the results in a timely manner hence the results are announced using partial samples which have biases.\r\n","content":"Mexican electoral<br>quick count night<br>with R","group":"Room 3","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"bfd33cd0-3fb2-40d9-b7dd-cc894ba8c3d1","start":"2020-01-30 15:05:00","end":"2020-01-30 15:10:00","title":"Category: Lightning Talks\nTitle: Learn to teach, for goodness sake.\nTime: 03:05PM to 03:10PM\nSpeaker(s): Mike K Smith (Pfizer, Senior Director, Statistics)\n\nEven though I’ve completed 4 marathons, you certainly shouldn’t come to me for a training plan on how to achieve your goals for any race you’re about to run. So why do we often turn to “experienced R users” to help us learn R or train an organization? The RStudio certified trainers have been taught modern, evidence-based teaching practices which they use in planning training sessions in order to help delegates achieve THEIR learning goals effectively in a given time-frame. My talk will illustrate some of these teaching concepts and how, by becoming a certified trainer, you can help others learn about R more effectively.\r\n","content":"Learn to teach, for<br>goodness sake.","group":"Room 2","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"225f8bda-d991-4d46-b67f-e7bb69c40af3","start":"2020-01-30 15:05:00","end":"2020-01-30 15:10:00","title":"Category: Lightning Talks\nTitle: Rproject templates to automate and standardize your workflow\nTime: 03:05PM to 03:10PM\nSpeaker(s): Caroline Ledbetter (University of Colorado, Sr Professional Research Assitant)\n\nMany teams and organizations have tasks and structures that are standard across projects. Lack of consistency and documentation can lead to lost productivity when team members join collaborations or previous work is consulted by your future self. Setting up folder structures can be particularly tedious. This talk will demonstrate using Rstudio project templates as part of an organizational package to automatically setup file structures, establish git repositories and add standardized readme files. It will also show how including report templates for Rmarkdown files can lead to more consistent and professional reports. Project info can be optionally stored so that project information can be easily added automatically to the top of reports and included in snippets for code file headers. Creating standard, easy to implement documentation and procedures can be particularly effective in encouraging skeptical collaborators to use git and Rmarkdown. Organizational packages can also be a great place to house functions that are specific and common to an organizations needs. The talk will showcase this functionality using the CIDAtools package that we developed. While the CIDAtools package was developed to address issues that sometimes arise from the less structured environment of academia, the tools presented can be equally useful in an industry setting.\r\n","content":"Rproject templates<br>to automate and<br>standardize your<br>workflow","group":"Room 3","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"c6593c42-1a58-48ca-bb19-2816cc125e99","start":"2020-01-30 15:10:00","end":"2020-01-30 15:15:00","title":"Category: Lightning Talks\nTitle: Learning by Teaching: Mentoring at the R4DS Online Learning Community\nTime: 03:10PM to 03:15PM\nSpeaker(s): Jon Harmon (Macmillan Learning, Senior Data Scientist)\n\nI host a weekly R Office Hour on the R4DS Online Learning Community Slack. By doing so, I have learned more about R than I ever would have thought. Here I'll present concrete examples of how R users can participate in the R community to expand their skills. R users of all skill levels can develop their skills by helping one another learn. Committing to help people with their coding challenges leads to exploration of answers in areas you might otherwise not examine.\r\n","content":"Learning by<br>Teaching: Mentoring<br>at the R4DS Online<br>Learning Community","group":"Room 2","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"0fa64705-d9f8-43f1-849a-14189afe0d41","start":"2020-01-30 15:10:00","end":"2020-01-30 15:15:00","title":"Category: Lightning Talks\nTitle: Sound annotation with Shiny and wavesurfer\nTime: 03:10PM to 03:15PM\nSpeaker(s): Athos Damiani (R6, Founder/Statistician)\n\nWe observed a huge improvements of Machine Learning tools but the main effort were to help at post annotated dataset step. We still struggle to build a trusty pipeline to make these annotations. The package wavesurfer brings to R users the ability to annotate audio files with ease and reliability, exploring the friendly user interface of Shiny to make this hard and laborious part of the project more joyful and efficient.\r\n","content":"Sound annotation<br>with Shiny and<br>wavesurfer","group":"Room 3","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"7bcb42c5-1005-4724-99a6-97dcd8e4ecbd","start":"2020-01-30 15:15:00","end":"2020-01-30 15:20:00","title":"Category: Lightning Talks\nTitle: Every voice matters: An analysis of @WeAreRLadies\nTime: 03:15PM to 03:20PM\nSpeaker(s): Katherine Simeon (Northwestern University)\n\nAs a rotating curation, @WeAreRLadies is a twitter account that has a different curator (i.e., tweeter) each week with a mission to highlight female and minority genders and their work in R. So far, curators have tweeted from 18 different countries and represent a variety of domains and levels of R expertise, ranging from R novices to those developing their own packages. With 45 R-Ladies curators to date, the account has become a popular R-related twitter resource, gaining more than 13,000 followers in the past year and hundreds of interactions each week. This talk will present a text analysis and reflection on over a year of Twitter text data from @WeAreRLadies. As the founder and maintainer of this account, I witness firsthand the bidirectional relationship between one’s learning journey and their use of R. In this talk, I will attempt to quantify this through a text analysis that explores how one’s experiences learning and using R relates to how they talk (or tweet) about it. By analyzing tweet text as well as other metrics provided by twitter (e.g., number of likes, replies, and clicks), I will showcase different ways curators have engaged with the R Twitter community and explore how account engagement has changed as the number of curators and followers continue to grow. I will also discuss how curators’ different areas of expertise have resulted in tweets and discussions that both demonstrate the variety of tools available in R, and spotlight unifying ideas and best practices in R programming. Finally, I will reflect on lessons learned and future directions for @WeAreRLadies, as well as its contribution to the R-Ladies Global initiative. Overall, this talk will discuss how diverse perspectives of @WeAreRLadies curators have enriched the conversations in the R Twitter community by validating different learning journeys and by promoting and amplifying underrepresented voices.\r\n","content":"Every voice<br>matters: An<br>analysis of<br>@WeAreRLadies","group":"Room 3","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"5d786f67-72c4-4ae9-b056-22d95922b4d2","start":"2020-01-30 15:15:00","end":"2020-01-30 15:20:00","title":"Category: Lightning Talks\nTitle: Peer review in data science courses\nTime: 03:15PM to 03:20PM\nSpeaker(s): Therese Anders (Hertie School, Postdoctoral research fellow)\n\nPeer review enables instructors of large data science classes to provide substantive feedback to students beyond what is feasible with standard code review via automated grading and continuous integration. It facilitates peer learning, which is shown in literature to have positive learning outcomes, and can reduce the burden of grading by course staff. The ghclass package provides a suite of functions to manage courses via GitHub repositories. The package has recently been supplemented with the functionality to implement peer review. Developed during my 2019 summer internship with RStudio in collaboration with my mentor Mine Çetinkaya-Rundel, the peer review functions in ghclass interface with the GitHub API to create review repositories, move files between authors and reviewers, submit feedback, and collect grades. In this presentation, I will give a demonstration of the peer review functions in ghclass. A set of six functions allows instructors to 1) create a random review roster, 2) set up the review repository infrastructure within a GitHub organization, 3) move assignments from authors to reviewers, 4) collect grades, 5) return the feedback, and 6) obtain a rating of the review from the authors. I reflect on the pedagogy of implementing peer review in introductory data science classes and talk about lessons learned from a real-world test run of the package in the Fall semester 2019 at the University of Edinburgh, conducted by Mine Çetinkaya-Rundel. The presentation highlights ghclass as an R command-line based, open source, low profile, and powerful solution to enable peer review in classes ranging from a size of two to approximately 400 students.\r\n","content":"Peer review in data<br>science courses","group":"Room 2","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"247af970-1756-499b-923a-c688658f2b37","start":"2020-01-30 15:20:00","end":"2020-01-30 15:25:00","title":"Category: Lightning Talks\nTitle: The Five Principles of Data Science Education\nTime: 03:20PM to 03:25PM\nSpeaker(s): Hunter Glanz (California Polytechnic State University , Dr.)\n\nIn this talk, I will outline a unified philosophy of data science education, and provide tips and tools for implementing these principles in the classroom using R and RStudio. Although data science as a professional discipline is well-established, its pedagogy is still in a period of growth. Even within a single university, multiple data science courses may be offered across different departments leading to inevitable redundancy of efforts amidst rich domain-specific innovations. My experience as an instructor in many such courses has lead me to five principles that transcend domain, context, and choice of language: reproducibility, communication, version control, practical application, and data ethics. For each of these full-stack themes, I will share examples of how to leverage tools in R and RStudio to enhance learning.\r\n","content":"The Five Principles<br>of Data Science<br>Education","group":"Room 2","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"3b5ecb40-f46d-4275-95df-acdba038b2e0","start":"2020-01-30 15:20:00","end":"2020-01-30 15:25:00","title":"Category: Lightning Talks\nTitle: Lessons about R I learned from my cat\nTime: 03:20PM to 03:25PM\nSpeaker(s): Amanda Gadrow (RStudio, Director of QA and Support)\n\nForming good development habits for R projects is pretty straight-forward if you follow the lessons I've learned from my cat, whose advice includes \"be lazy\", \"keep your claws sharp\", and \"land on your feet\". Attendees of this talk will learn how to make life easier on colleagues and their future selves by using simple software engineering best practices to build their current projects. Each point will come with cat photos and code samples, the two best parts of the Internet!\r\n","content":"Lessons about R I<br>learned from my cat","group":"Room 3","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"58e23df9-0db8-4c65-a10d-bdb74c5a25b6","start":"2020-01-30 15:25:00","end":"2020-01-30 15:30:00","title":"Category: Lightning Talks\nTitle: TidyBlocks: using the language of the tidyverse in a blocks-based interface\nTime: 03:25PM to 03:30PM\nSpeaker(s): Maya Gans\n\nAs an intern at RStudio, I developed a blocks-based coding language mimicking the verb-driven programming of the tidyverse. Blocks-based coding environments are a popular way to introduce programming to novices. Instead of typing in code, users click blocks together to create loops, conditionals, and expressions. Studies have shown that students are more successful and more interested in coding when introduced through a block-based language like Scratch or Snap! rather than a text-based language. However, it's much easier to express control flow with these tools than to manipulate data: adding 1 to a variable requires several steps, and there are no built-in capabilities for working with tabular data. On the other hand, R's tidyverse libraries provide a predictable, consistent grammar for doing these tasks. As an intern at RStudio, I developed a blocks-based coding language mimicking the verb driven programming of the tidyverse. Tabular data can be imported and transformed using verbs like filter, select, and summarize, and functions can be strung together using pipes, which users can think of as meaning \"and then\". The talk will include a demo of TidyBlocks and a description of how we're testing and improving it.\r\n","content":"TidyBlocks: using<br>the language of the<br>tidyverse in a<br>blocks-based","group":"Room 2","type":"range","style":"color: white; background-color: #BDB985b3; border-color: #BDB985;"},{"id":"cb8daf5a-42a2-4f4b-bb6a-14248bc8dbfd","start":"2020-01-30 16:00:00","end":"2020-01-30 17:00:00","title":"Category: Keynote\nTitle: NSSD Episode 100\nTime: 04:00PM to 05:00PM\nSpeaker(s): Hilary Parker (Stitch Fix, Data Scientist); Roger Peng (Johns Hopkins Bloomberg School of Public Health, Professor of Biostatistics)\n\nIn episode 100 of Not So Standard Deviations, the first ever episode prepared in advance, Hilary and Roger discuss creativity, its role in data science, and how it can be fostered through conversation. Also, follow up on coffee and oat milk.\r\n","content":"NSSD Episode 100","group":"Room 2","type":"range","style":"color: white; background-color: #0B4947b3; border-color: #0B4947;"},{"id":"15f13b56-fac6-4dfa-ba14-f5168917d79c","start":"2020-01-30 17:00:00","end":"2020-01-30 17:05:00","title":"Category: \nTitle: Wrap up\nTime: 05:00PM to 05:05PM\nSpeaker(s): Hadley Wickham (RStudio, Chief Scientist)\n\n","content":"Wrap up","group":"Room 2","type":"range","style":"color: white; background-color: #FED439b3; border-color: #FED439;"}],"groups":[{"id":"Room 1","content":"Room 1","order":"1"},{"id":"Room 2","content":"Room 2","order":"2"},{"id":"Room 3","content":"Room 3","order":"3"},{"id":"Room 4","content":"Room 4","order":"4"}],"showZoom":true,"zoomFactor":0.5,"fit":true,"options":{"stack":false,"stackSubgroups":false,"horizontalScroll":true,"zoomKey":"ctrlKey","width":"100%","format":{"minorLabels":{"minute":"LT","hour":"LT"}},"end":"2020-01-29 11:00:00","hiddenDates":{"start":"2020-01-29 18:00:00","end":"2020-01-30 08:00:00"}},"height":null,"api":[]},"evals":[],"jsHooks":[]}</script>
<p><span style="font-size: xx-large;">ℹ</span></p>
<blockquote>
<ul>
<li>Hover over a session to get more info about the session and the speaker.</li>
<li>Click and hold your mouse inside the schedule window, and them move your mouse left or right to scroll through
additional dates/times.</li>
<li>Press the +/- buttons to zoom in or out on the schedule.</li>
</ul>
</blockquote>
<p />
<hr>
<p>We could make this fancier by adding buttons to jump to specific time ranges, a dropdown to select the times for a
specific session, etc. But… let’s just take the win, go home, and eat some spaghetti with syrup to celebrate!</p>
<div style="margin:auto; width:480px;">
<a href="https://media.giphy.com/media/slOhiKAVFgwr6/giphy.gif">
<img style="width:100%;" src="youdidit.gif" alt="You did it, congratulations!!!" />
<figcaption>
<img style="width:120px; float:right; padding-top:5px;" src="giphy.png" alt="Giphy logo" />
</figcaption>
<p></a></p>
</div>
<p><br></p>
</div>


        
          <div class="blog-tags">
            
              <a href="//tags/r/">R</a>&nbsp;
            
              <a href="//tags/rstudio/">RStudio</a>&nbsp;
            
              <a href="//tags/conference/">conference</a>&nbsp;
            
              <a href="//tags/scraping/">scraping</a>&nbsp;
            
          </div>
        

        
            <hr/>
            <section id="social-share">
              <div class="list-inline footer-links">
                

<div class="share-box" aria-hidden="true">
    <ul class="share">
      
      <li>
        <a href="//twitter.com/share?url=%2fpost%2f2020-01-20-schedule-for-rstudio-conf-2020l-talks%2f&amp;text=Schedule%20for%20rstudio%3a%3aconf%282020L%29%20talks&amp;via=embiggenData" target="_blank" title="Share on Twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.facebook.com/sharer/sharer.php?u=%2fpost%2f2020-01-20-schedule-for-rstudio-conf-2020l-talks%2f" target="_blank" title="Share on Facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//reddit.com/submit?url=%2fpost%2f2020-01-20-schedule-for-rstudio-conf-2020l-talks%2f&amp;title=Schedule%20for%20rstudio%3a%3aconf%282020L%29%20talks" target="_blank" title="Share on Reddit">
          <i class="fab fa-reddit"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.linkedin.com/shareArticle?url=%2fpost%2f2020-01-20-schedule-for-rstudio-conf-2020l-talks%2f&amp;title=Schedule%20for%20rstudio%3a%3aconf%282020L%29%20talks" target="_blank" title="Share on LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.stumbleupon.com/submit?url=%2fpost%2f2020-01-20-schedule-for-rstudio-conf-2020l-talks%2f&amp;title=Schedule%20for%20rstudio%3a%3aconf%282020L%29%20talks" target="_blank" title="Share on StumbleUpon">
          <i class="fab fa-stumbleupon"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.pinterest.com/pin/create/button/?url=%2fpost%2f2020-01-20-schedule-for-rstudio-conf-2020l-talks%2f&amp;description=Schedule%20for%20rstudio%3a%3aconf%282020L%29%20talks" target="_blank" title="Share on Pinterest">
          <i class="fab fa-pinterest"></i>
        </a>
      </li>
    </ul>
  </div>
  

              </div>
            </section>
        

        
          

          
        
      </article>

      
        <ul class="pager blog-pager">
          
          
        </ul>
      


      
        
        
      

    </div>
  </div>
</div>

      
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
                <a href="mailto:danielrlabar@gmail.com" title="Email me">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://twitter.com/embiggenData" title="Twitter">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://linkedin.com/in/dan-labar-b4b6b54" title="LinkedIn">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://stackoverflow.com/users/1344789/dnlbrky" title="StackOverflow">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-stack-overflow fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          <li>
            <a href="" title="RSS">
              <span class="fa-stack fa-lg">
                <i class="fas fa-circle fa-stack-2x"></i>
                <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          
            
              <a href="yourwebsite.com">Dan LaBar</a>
            
          

          &nbsp;&bull;&nbsp;&copy;
          
            2020
          

          
            &nbsp;&bull;&nbsp;
            <a href="/">DL;DS</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.62.2</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="/js/main.js"></script>
<script src="/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script> renderMathInElement(document.body); </script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="/js/load-photoswipe.js"></script>









    
  </body>
</html>

